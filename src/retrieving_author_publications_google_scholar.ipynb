{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_GS = True\n",
    "\n",
    "# change for different location\n",
    "# locations: \"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"\n",
    "\n",
    "location = \"ravensburg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "# open session for html requests\n",
    "SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author names\n",
    "pd_employees = pd.read_csv(f'../data/{current_year}/employees_{location}.csv')\n",
    "author_names = pd_employees['employee_name_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    random_wait_time = random.randint(15,25)\n",
    "    time.sleep(random_wait_time)\n",
    "\n",
    "    try:\n",
    "        response = SESSION.get(url)\n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id_query(soup):\n",
    "    \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        # get user ID for query\n",
    "        query_with_id = soup.find(\"h4\", class_ = \"gs_rt2\").find(\"a\").get('href')\n",
    "        \n",
    "    else:\n",
    "        query_with_id = None\n",
    "        print(f\"{author_name} does not have a profile on Google Scholar.\")\n",
    "        \n",
    "    return query_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_profile(soup):   \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(string_with_numbers):\n",
    "    if not string_with_numbers:\n",
    "        return None\n",
    "    \n",
    "    tokens = string_with_numbers.split(\" \")\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if not re.search(\"[0-9]\", token):\n",
    "            cleaned_tokens.append(token)\n",
    "    return \" \".join(cleaned_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publication_entries(soup):\n",
    "    \n",
    "    query_with_id = get_author_id_query(soup)\n",
    "    soup = None\n",
    "\n",
    "    if query_with_id != None:\n",
    "        # get HTML response for author profile\n",
    "        response = get_source(f\"https://scholar.google.com{query_with_id}&cstart=0&pagesize=1001\") # the last part is to get all entries\n",
    "\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.html.raw_html)\n",
    "\n",
    "            #get article entries\n",
    "            all_article_entries = soup.find_all(\"tr\", class_ = \"gsc_a_tr\")\n",
    "        \n",
    "    else:\n",
    "        all_article_entries = None\n",
    "        \n",
    "    return all_article_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(entry):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    number_citations = \"\"\n",
    "    \n",
    "    # get authors and journal\n",
    "    if entry.find(\"div\", class_ = \"gs_gray\"):\n",
    "        string_with_authors = entry.find(\"div\", class_ = \"gs_gray\").string\n",
    "        authors_list = string_with_authors.split(\",\")\n",
    "        \n",
    "        publisher_string = entry.find_all(\"div\", class_ = \"gs_gray\")[1].text\n",
    "        publisher = publisher_string.split(\",\")[0] #also has ISBN\n",
    "        publisher = remove_numbers(publisher)\n",
    "\n",
    "    # get title\n",
    "    if entry.find(\"a\", class_=\"gsc_a_at\"):\n",
    "        publication_title = entry.find(\"a\", class_=\"gsc_a_at\").string\n",
    "\n",
    "    # get year\n",
    "    if entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\"):\n",
    "        publication_year = entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\").string\n",
    "\n",
    "    # get number of citations\n",
    "    if entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\"):\n",
    "        number_citations = entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\").string\n",
    "        \n",
    "    \n",
    "    \n",
    "    return publication_title, publication_year, authors_list, number_citations, publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(soup, author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    \n",
    "    all_publication_entries = get_all_publication_entries(soup)\n",
    "    \n",
    "    if all_publication_entries:\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, number_citations, publisher = get_publication_info(publication_entry)\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(soup, author_name):\n",
    "\n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    \n",
    "    number_publications = 1\n",
    "\n",
    "    search_result = soup.find(\"div\", id=\"gs_ab_md\").find(\"div\", class_=\"gs_ab_mdw\").text\n",
    "    \n",
    "    if re.search(\" [0-9]* result\", search_result):\n",
    "        number_publications = int(re.search(\" [0-9]* result\", search_result).group().strip().split(\" \")[0])\n",
    "        \n",
    "    # first page\n",
    "    \n",
    "    for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "        # and journal\n",
    "        if entry.find(\"div\", class_=\"gs_a\"):\n",
    "            # get authors\n",
    "            authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "            # get year\n",
    "            if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "            else:\n",
    "                publication_year = None\n",
    "\n",
    "            # get publisher\n",
    "            journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "            if \",\" in journal_string:\n",
    "                publisher = journal_string.split(\",\")[0]\n",
    "            else:\n",
    "                publisher = None\n",
    "                \n",
    "            publisher = remove_numbers(publisher)\n",
    "\n",
    "        # get title\n",
    "        if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "            publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "        # get number of citations\n",
    "        footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "        number_citations = None\n",
    "\n",
    "        for element in footer_elements:\n",
    "            if \"Cited by\" in element.text:\n",
    "                number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        publishers.append(publisher)\n",
    "        authors_lists.append(authors_list)\n",
    "        number_citations_list.append(number_citations)\n",
    "        author_name_list.append(author_name)\n",
    "\n",
    "        \n",
    "\n",
    "    # all other pages\n",
    "    for current_page in range(10, number_publications, 10):\n",
    "        next_page = get_source(f\"https://scholar.google.cz/scholar?start={current_page}&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "        soup = BeautifulSoup(next_page.html.raw_html)\n",
    "\n",
    "        for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "            # and journal\n",
    "            if entry.find(\"div\", class_=\"gs_a\"):\n",
    "                # get authors\n",
    "                authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "                # get year\n",
    "                if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                    publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "                else:\n",
    "                    publication_year = None\n",
    "\n",
    "                # get publisher\n",
    "                journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "                if \",\" in journal_string:\n",
    "                    publisher = journal_string.split(\",\")[0]\n",
    "                else:\n",
    "                    publisher = None\n",
    "                    \n",
    "                publisher = remove_numbers(publisher)\n",
    "\n",
    "            # get title\n",
    "            if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "                publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "            # get number of citations\n",
    "            footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            number_citations = None\n",
    "            \n",
    "            for element in footer_elements:\n",
    "                if \"Cited by\" in element.text:\n",
    "                    number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list}\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No publications found for Franziska Baar.\n",
      "No publications found for Jürgen Brath.\n",
      "No publications found for Bhagyaraj Dharmana.\n",
      "No publications found for Vera Engelbart.\n",
      "No publications found for Patrick Gieger.\n",
      "No publications found for Chaitanya Grandhi.\n",
      "No publications found for Mathias Hassenstein.\n",
      "No publications found for Rajesh Kallur Krishnamoorthy.\n",
      "No publications found for John-Dean Kasher.\n",
      "No publications found for Christina Krumm.\n",
      "No publications found for Albrecht Linkohr.\n",
      "No publications found for Holger Lund.\n",
      "No publications found for Stefan Luppold.\n",
      "No publications found for Thomas Mannchen.\n",
      "No publications found for Conny Mayer-Bonde.\n",
      "No publications found for Christoph Moser.\n",
      "No publications found for Herbert Moser.\n",
      "No publications found for Bodo Möslein-Tröppner.\n",
      "No publications found for Maren Müller.\n",
      "No publications found for Christoph Neef.\n",
      "No publications found for Thomas Nickel.\n",
      "No publications found for Uwe Nölte.\n",
      "No publications found for Marc Nutzmann.\n",
      "No publications found for Alexandra Ottler.\n",
      "No publications found for Simon Ottler.\n",
      "No publications found for Boitumelo Pooe.\n",
      "No publications found for Holger Purol.\n",
      "No publications found for Hans Putnoki.\n",
      "No publications found for Petra Radke.\n",
      "No publications found for Volker Radke.\n",
      "No publications found for Bernd Radtke.\n",
      "No publications found for Nehalben Ranabhatt.\n",
      "No publications found for Markus Rathgeb.\n",
      "No publications found for Konrad Reif.\n",
      "No publications found for Karin Reinhard.\n",
      "No publications found for René Resch.\n",
      "No publications found for Simon Riedle.\n",
      "No publications found for Bernd Rieger.\n",
      "No publications found for Patrick Roßmann.\n",
      "No publications found for Wilhelm Ruckdeschel.\n",
      "No publications found for Lars Ruhbach.\n",
      "No publications found for Navid Sardarabady.\n",
      "No publications found for Thorsten Sauer.\n",
      "No publications found for Stephan Sauter.\n",
      "No publications found for Susanne Schandl.\n",
      "No publications found for Manfred Schertler-Rock.\n",
      "No publications found for Andreas Schilling.\n",
      "No publications found for Jürgen Schneider.\n",
      "No publications found for Heike Schwadorf.\n",
      "No publications found for Frederike Schwenke.\n",
      "No publications found for Thomas Seemann.\n",
      "No publications found for Jan Specht.\n",
      "No publications found for Joachim Sprink.\n",
      "No publications found for Heike Stahl.\n",
      "No publications found for Almut Steinbach.\n",
      "No publications found for Michael Streich.\n",
      "No publications found for Günther Suchy.\n",
      "No publications found for Ulrike Tennagen.\n",
      "No publications found for Friedrich Then Bergh.\n",
      "No publications found for Jens Timmermann.\n",
      "No publications found for Torsten Widmann.\n",
      "No publications found for Stefan Zink.\n"
     ]
    }
   ],
   "source": [
    "# loop through authors and collect publications in dataframe\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS'])\n",
    "\n",
    "for author_name in author_names:\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name_string = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://scholar.google.cz/scholar?hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    if has_profile(soup):\n",
    "        pd_publications = get_dataframe_with_publications(soup, author_name)\n",
    "\n",
    "    else:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(soup, author_name)\n",
    "        \n",
    "    if pd_publications.empty:\n",
    "        print(f\"No publications found for {author_name}.\")\n",
    "    \n",
    "    else:\n",
    "        pd_result = pd_result.append(pd_publications, ignore_index=True, sort=False)\n",
    "\n",
    "pd_result = pd_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_GS:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_gs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>PUB_TITLE</th>\n",
       "      <th>PUB_YEAR</th>\n",
       "      <th>PUB_AUTHORS</th>\n",
       "      <th>PUB_PUBLISHER</th>\n",
       "      <th>PUB_CITATIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atheer Al-Tameemi</td>\n",
       "      <td>Estimation of planetary surface ages using ima...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[A Al]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Asche</td>\n",
       "      <td>Validation of the COMPASS force field for comp...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[TS Asche,  P Behrens,  AM Schneider]</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Asche</td>\n",
       "      <td>[BOOK][B] Das Sicherheitsverhalten von Konsume...</td>\n",
       "      <td>1990</td>\n",
       "      <td>[T Asche ]</td>\n",
       "      <td>None</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas Asche</td>\n",
       "      <td>Die Ergebnisse der empirischen Analyse zum Sic...</td>\n",
       "      <td>1990</td>\n",
       "      <td>[T Asche]</td>\n",
       "      <td>Das Sicherheitsverhalten von Konsumenten</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas Asche</td>\n",
       "      <td>Die Datengewinnung zur Analyse des Sicherheits...</td>\n",
       "      <td>1990</td>\n",
       "      <td>[T Asche]</td>\n",
       "      <td>Das Sicherheitsverhalten von Konsumenten</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>Frank Lehmann</td>\n",
       "      <td>\" Last-Mile\" preparation for a potential disas...</td>\n",
       "      <td>2009</td>\n",
       "      <td>[H Taubenböck,  N Goseberg,  N Setiadi…]</td>\n",
       "      <td>… Hazards and Earth …</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Frank Lehmann</td>\n",
       "      <td>Influence of surface conditioning and cleaning...</td>\n",
       "      <td>2011</td>\n",
       "      <td>[A Attia,  F Lehmann,  M Kern]</td>\n",
       "      <td>Dental Materials</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Frank Lehmann</td>\n",
       "      <td>Acoustic emission analysis for the quantificat...</td>\n",
       "      <td>2012</td>\n",
       "      <td>[K Van Tittelboom,  N De Belie,  F Lehmann…]</td>\n",
       "      <td>… and Building Materials</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Frank Lehmann</td>\n",
       "      <td>[HTML][HTML] Interleukin-33-activated islet-re...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[E Dalmas,  FM Lehmann,  E Dror,  S Wueest,  C...</td>\n",
       "      <td>Immunity</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Frank Lehmann</td>\n",
       "      <td>Relating ligand binding to activation gating i...</td>\n",
       "      <td>2007</td>\n",
       "      <td>[C Biskup,  J Kusch,  E Schulz,  V Nache,  F S...</td>\n",
       "      <td>Nature</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUTHOR_NAME                                          PUB_TITLE  \\\n",
       "0     Atheer Al-Tameemi  Estimation of planetary surface ages using ima...   \n",
       "1          Thomas Asche  Validation of the COMPASS force field for comp...   \n",
       "2          Thomas Asche  [BOOK][B] Das Sicherheitsverhalten von Konsume...   \n",
       "3          Thomas Asche  Die Ergebnisse der empirischen Analyse zum Sic...   \n",
       "4          Thomas Asche  Die Datengewinnung zur Analyse des Sicherheits...   \n",
       "...                 ...                                                ...   \n",
       "1052      Frank Lehmann  \" Last-Mile\" preparation for a potential disas...   \n",
       "1053      Frank Lehmann  Influence of surface conditioning and cleaning...   \n",
       "1054      Frank Lehmann  Acoustic emission analysis for the quantificat...   \n",
       "1055      Frank Lehmann  [HTML][HTML] Interleukin-33-activated islet-re...   \n",
       "1056      Frank Lehmann  Relating ligand binding to activation gating i...   \n",
       "\n",
       "     PUB_YEAR                                        PUB_AUTHORS  \\\n",
       "0        2018                                             [A Al]   \n",
       "1        2017              [TS Asche,  P Behrens,  AM Schneider]   \n",
       "2        1990                                         [T Asche ]   \n",
       "3        1990                                          [T Asche]   \n",
       "4        1990                                          [T Asche]   \n",
       "...       ...                                                ...   \n",
       "1052     2009           [H Taubenböck,  N Goseberg,  N Setiadi…]   \n",
       "1053     2011                     [A Attia,  F Lehmann,  M Kern]   \n",
       "1054     2012       [K Van Tittelboom,  N De Belie,  F Lehmann…]   \n",
       "1055     2017  [E Dalmas,  FM Lehmann,  E Dror,  S Wueest,  C...   \n",
       "1056     2007  [C Biskup,  J Kusch,  E Schulz,  V Nache,  F S...   \n",
       "\n",
       "                                  PUB_PUBLISHER PUB_CITATIONS  \n",
       "0                                          None           NaN  \n",
       "1                                          None            14  \n",
       "2                                          None            26  \n",
       "3      Das Sicherheitsverhalten von Konsumenten           NaN  \n",
       "4      Das Sicherheitsverhalten von Konsumenten           NaN  \n",
       "...                                         ...           ...  \n",
       "1052                      … Hazards and Earth …           151  \n",
       "1053                           Dental Materials           148  \n",
       "1054                   … and Building Materials           142  \n",
       "1055                                   Immunity            85  \n",
       "1056                                     Nature           124  \n",
       "\n",
       "[1057 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
