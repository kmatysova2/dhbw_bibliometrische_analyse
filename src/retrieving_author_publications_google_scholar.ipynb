{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_GS = True\n",
    "\n",
    "# change for different location\n",
    "\n",
    "# locations: ravensburg, mannheim, heidenheim, karlsruhe, campus-horb, stuttgart\n",
    "# locations: heilbronn, loerrach, mosbach, villingen-schwenningen\n",
    "\n",
    "location = \"ravensburg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "# open session for html requests\n",
    "SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author names\n",
    "pd_employees = pd.read_csv(f'../data/{current_year}/employees_{location}.csv')\n",
    "author_names = pd_employees['employee_name_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    random_wait_time = random.randint(1,3)\n",
    "    time.sleep(random_wait_time)\n",
    "\n",
    "    try:\n",
    "        response = SESSION.get(url)\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            raise requests.exceptions.RequestException(f\"Too many requests have been made. Stopped at url: {url}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id_query(soup):\n",
    "    \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        # get user ID for query\n",
    "        query_with_id = soup.find(\"h4\", class_ = \"gs_rt2\").find(\"a\").get('href')\n",
    "        \n",
    "    else:\n",
    "        query_with_id = None\n",
    "        print(f\"{author_name} does not have a profile on Google Scholar.\")\n",
    "        \n",
    "    return query_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_profile(soup):   \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(string_with_numbers):\n",
    "    if not string_with_numbers:\n",
    "        return None\n",
    "    \n",
    "    tokens = string_with_numbers.split(\" \")\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if not re.search(\"[0-9]\", token):\n",
    "            cleaned_tokens.append(token)\n",
    "    return \" \".join(cleaned_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publication_entries(soup):\n",
    "    \n",
    "    query_with_id = get_author_id_query(soup)\n",
    "    soup = None\n",
    "\n",
    "    if query_with_id != None:\n",
    "        # get HTML response for author profile\n",
    "        response = get_source(f\"https://scholar.google.com{query_with_id}&cstart=0&pagesize=1001\") # the last part is to get all entries\n",
    "\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.html.raw_html)\n",
    "\n",
    "            #get article entries\n",
    "            all_article_entries = soup.find_all(\"tr\", class_ = \"gsc_a_tr\")\n",
    "        \n",
    "    else:\n",
    "        all_article_entries = None\n",
    "        \n",
    "    return all_article_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(entry):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    number_citations = \"\"\n",
    "    \n",
    "    # get authors and journal\n",
    "    if entry.find(\"div\", class_ = \"gs_gray\"):\n",
    "        string_with_authors = entry.find(\"div\", class_ = \"gs_gray\").string\n",
    "        authors_list = string_with_authors.split(\",\")\n",
    "        \n",
    "        publisher_string = entry.find_all(\"div\", class_ = \"gs_gray\")[1].text\n",
    "        publisher = publisher_string.split(\",\")[0] #also has ISBN\n",
    "        publisher = remove_numbers(publisher)\n",
    "\n",
    "    # get title\n",
    "    if entry.find(\"a\", class_=\"gsc_a_at\"):\n",
    "        publication_title = entry.find(\"a\", class_=\"gsc_a_at\").string\n",
    "\n",
    "    # get year\n",
    "    if entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\"):\n",
    "        publication_year = entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\").string\n",
    "\n",
    "    # get number of citations\n",
    "    if entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\"):\n",
    "        number_citations = entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\").string\n",
    "        \n",
    "    \n",
    "    \n",
    "    return publication_title, publication_year, authors_list, number_citations, publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(soup, author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    all_publication_entries = get_all_publication_entries(soup)\n",
    "    \n",
    "    if all_publication_entries:\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, number_citations, publisher = get_publication_info(publication_entry)\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "            updated_list.append(datetime.date.today())\n",
    "\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'UPDATED': updated_list}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(soup, author_name):\n",
    "\n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    number_publications = 1\n",
    "    \n",
    "    if not soup or not soup.find(\"div\", id=\"gs_ab_md\"):\n",
    "        return pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS', 'UPDATED'])\n",
    "\n",
    "    search_result = soup.find(\"div\", id=\"gs_ab_md\").find(\"div\", class_=\"gs_ab_mdw\").text\n",
    "    \n",
    "    if re.search(\" [0-9]* result\", search_result):\n",
    "        number_publications = int(re.search(\" [0-9]* result\", search_result).group().strip().split(\" \")[0])\n",
    "        \n",
    "    # first page\n",
    "    \n",
    "    for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "        # and journal\n",
    "        if entry.find(\"div\", class_=\"gs_a\"):\n",
    "            # get authors\n",
    "            authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "            # get year\n",
    "            if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "            else:\n",
    "                publication_year = None\n",
    "\n",
    "            # get publisher\n",
    "            journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "            if \",\" in journal_string:\n",
    "                publisher = journal_string.split(\",\")[0]\n",
    "            else:\n",
    "                publisher = None\n",
    "                \n",
    "            publisher = remove_numbers(publisher)\n",
    "\n",
    "        # get title\n",
    "        if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "            publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "        # get number of citations\n",
    "        footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "        number_citations = None\n",
    "\n",
    "        for element in footer_elements:\n",
    "            if \"Cited by\" in element.text:\n",
    "                number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        publishers.append(publisher)\n",
    "        authors_lists.append(authors_list)\n",
    "        number_citations_list.append(number_citations)\n",
    "        author_name_list.append(author_name)\n",
    "        updated_list.append(datetime.date.today())\n",
    "\n",
    "        \n",
    "\n",
    "    # all other pages\n",
    "    for current_page in range(10, number_publications, 10):\n",
    "        next_page = get_source(f\"https://scholar.google.cz/scholar?start={current_page}&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "        soup = BeautifulSoup(next_page.html.raw_html)\n",
    "\n",
    "        for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "            # and journal\n",
    "            if entry.find(\"div\", class_=\"gs_a\"):\n",
    "                # get authors\n",
    "                authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "                # get year\n",
    "                if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                    publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "                else:\n",
    "                    publication_year = None\n",
    "\n",
    "                # get publisher\n",
    "                journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "                if \",\" in journal_string:\n",
    "                    publisher = journal_string.split(\",\")[0]\n",
    "                else:\n",
    "                    publisher = None\n",
    "                    \n",
    "                publisher = remove_numbers(publisher)\n",
    "\n",
    "            # get title\n",
    "            if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "                publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "            # get number of citations\n",
    "            footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            number_citations = None\n",
    "            \n",
    "            for element in footer_elements:\n",
    "                if \"Cited by\" in element.text:\n",
    "                    number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "            updated_list.append(datetime.date.today())\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'UPDATED': updated_list}\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names that are alrady in the database\n",
    "outcome_file = Path(f'../data/{current_year}/publications_{location}_gs.csv', index=False)\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS', 'UPDATED'])\n",
    "\n",
    "# don't use names that are recent enough\n",
    "if outcome_file.is_file():\n",
    "    pd_result = pd.read_csv(f'../data/{current_year}/publications_{location}_gs.csv')\n",
    "    authors_already_recent = []\n",
    "    \n",
    "    # update authors that have been updated more than 30 days ago\n",
    "    for author in pd_result[\"AUTHOR_NAME\"].unique():\n",
    "        if datetime.datetime.strptime(pd_result[pd_result['AUTHOR_NAME'] == author].iloc[0][\"UPDATED\"], \"%Y-%m-%d\").date() > (datetime.date.today() - datetime.timedelta(days=60)):\n",
    "            authors_already_recent.append(author)\n",
    "    \n",
    "    author_names = list(set(author_names) - set(authors_already_recent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No publications found for Bernd Radtke.\n",
      "No publications found for Michaela Bergmann.\n",
      "No publications found for Thomas Mannchen.\n",
      "No publications found for Conny Mayer-Bonde.\n",
      "No publications found for Joachim Güntzel.\n",
      "No publications found for Heike Stahl.\n",
      "No publications found for Mathias Hassenstein.\n",
      "No publications found for Harald Pfab.\n",
      "No publications found for Alexandra Ottler.\n",
      "No publications found for Karin Reinhard.\n",
      "No publications found for Udo Klaiber.\n",
      "No publications found for Markus Schatz.\n",
      "No publications found for Paul Kirchberg.\n",
      "No publications found for Markus Rathgeb.\n",
      "No publications found for Wilhelm Ruckdeschel.\n",
      "No publications found for Lars Ruhbach.\n",
      "No publications found for Alexander Dingeldey.\n",
      "No publications found for Petra Kroflin.\n",
      "No publications found for Friedrich Then Bergh.\n",
      "No publications found for Anja Brittner-Widmann.\n",
      "No publications found for Claudia Lembach.\n",
      "No publications found for Bhagyaraj Dharmana.\n",
      "Too many requests have been made. Stopped at url: https://scholar.google.cz/scholar?start=60&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22Martin+Zaefferer%22&btnG=\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fb3b6fc5c2ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mpd_publications\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataframe_with_publications_no_profile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthor_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpd_publications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-d9d3544deaeb>\u001b[0m in \u001b[0;36mget_dataframe_with_publications_no_profile\u001b[1;34m(soup, author_name)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcurrent_page\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_publications\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mnext_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"https://scholar.google.cz/scholar?start={current_page}&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_html\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gs_ri\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'html'"
     ]
    }
   ],
   "source": [
    "# loop through authors and collect publications in dataframe\n",
    "\n",
    "for author_name in author_names:\n",
    "\n",
    "    # get HTML response for author\n",
    "    author_name_string = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://scholar.google.cz/scholar?hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    if has_profile(soup):\n",
    "        pd_publications = get_dataframe_with_publications(soup, author_name)\n",
    "\n",
    "    else:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(soup, author_name)\n",
    "        \n",
    "    if pd_publications.empty:\n",
    "        print(f\"No publications found for {author_name}.\")\n",
    "    \n",
    "    else:\n",
    "        pd_result = pd_result.append(pd_publications, ignore_index=True, sort=False)\n",
    "\n",
    "pd_result = pd_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_GS:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_gs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>PUB_TITLE</th>\n",
       "      <th>PUB_YEAR</th>\n",
       "      <th>PUB_AUTHORS</th>\n",
       "      <th>PUB_PUBLISHER</th>\n",
       "      <th>PUB_CITATIONS</th>\n",
       "      <th>UPDATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Einführung in die Wirtschaftsinformatik: Ein f...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>['MA Bächle', ' S Daurer', ' A Kolb']</td>\n",
       "      <td>De Gruyter Oldenbourg</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Consumer Search Behavior on the Mobile Interne...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['S Daurer', ' D Molitor', ' M Spann', ' P Man...</td>\n",
       "      <td>Ross School of Business Paper</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Digitalisierung und Konvergenz von Online-und ...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>['S Daurer', ' D Molitor', ' M Spann']</td>\n",
       "      <td>Zeitschrift für Betriebswirtschaft (ZfB)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Assistive technology for independent living wi...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...</td>\n",
       "      <td>Health Policy and Technology</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Tell Me Where You Are and I’ll Tell You What Y...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['M Spann', ' D Molitor', ' S Daurer']</td>\n",
       "      <td>GfK Marketing Intelligence Review</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Measuring Individual Search Costs on the Mobil...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>['S Daurer', ' D Molitor', ' M Spann']</td>\n",
       "      <td>ECIS</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Potenziale integrierter Social Software-das Be...</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>['M Bächle', ' S Daurer']</td>\n",
       "      <td>HMD-Praxis der Wirtschaftsinformatik</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>The Impact of Smartphones, Barcode Scanning, a...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>['S Daurer', ' D Molitor', ' M Spann', ' P Man...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Parental control reversed: Using ADR for desig...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['T Mettler', ' M Bächle', ' S Daurer', ' A Ju...</td>\n",
       "      <td>ICIS Proceedings</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Application of Media Synchronicity Theory to C...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>['L Furmanek', ' S Daurer']</td>\n",
       "      <td>Proceedings of the International Conference on...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Consumer Preferences for Product Information a...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['J Fölting', ' S Daurer', ' M Spann']</td>\n",
       "      <td>Proceedings of the International Conference on...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>iCare—supporting people with increased need fo...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...</td>\n",
       "      <td>European Journal of Epidemiology (Supplement))</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>iCare – Supporting People with Increased Need ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['M BÄCHLE', ' S DAURER', ' A JUDT', ' T METTL...</td>\n",
       "      <td>Health – Exploring Complexity: An Interdiscipl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Chatbots as a User Interface for Assistive Tec...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...</td>\n",
       "      <td>Assistenztechnologien in der Arbeitswelt. Beit...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>iCare–Do-It-Yourself: Architektur ambienter As...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['A Judt', ' M Bächle', ' S Daurer', ' T Mettl...</td>\n",
       "      <td>Smart-Future-Living-Bodensee Conference</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Do‐It‐Yourself as a Means for Making Assistive...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>['T Mettler', ' S Daurer', ' MA Bächle', ' A J...</td>\n",
       "      <td>Information Systems Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Die Aufklärung und das Web 2.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>['MA Bächle', ' S Daurer']</td>\n",
       "      <td>Wirtschaftsinformatik und Management. DOI:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Digitizing Offline Search: An Empirical Analys...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>['D Molitor', ' S Daurer', ' M Spann', ' P Man...</td>\n",
       "      <td>Ross School of Business Paper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Notfallerkennung mit ambienten Assistenzsystem...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...</td>\n",
       "      <td>Usability Day XV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Sag mir, wo du bist und ich sage dir, was du w...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['M Spann', ' D Molitor', ' S Daurer']</td>\n",
       "      <td>GfK MIR - Marketingforschung für die Praxis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Adblocker: Bitte keine Werbung!</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['T Krohn', ' S Daurer']</td>\n",
       "      <td>Markenartikel – Fachmagazin für Markenführung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Adblocker</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['S Daurer', ' T Krohn']</td>\n",
       "      <td>MedienWirtschaft - Zeitschrift für Medienmanag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Location-based Services and Consumer Search on...</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>['S Daurer']</td>\n",
       "      <td>epubli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>IT-Strategie</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>['S Daurer']</td>\n",
       "      <td>IT für Existenzgründer und junge Unternehmen -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Stephan Daurer</td>\n",
       "      <td>Einkauf durch mobile Suche im Internet</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>['M Spann', ' S Daurer', ' D Molitor']</td>\n",
       "      <td>WISU - Das Wirtschaftsstudium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUTHOR_NAME                                          PUB_TITLE  \\\n",
       "586  Stephan Daurer  Einführung in die Wirtschaftsinformatik: Ein f...   \n",
       "587  Stephan Daurer  Consumer Search Behavior on the Mobile Interne...   \n",
       "588  Stephan Daurer  Digitalisierung und Konvergenz von Online-und ...   \n",
       "589  Stephan Daurer  Assistive technology for independent living wi...   \n",
       "590  Stephan Daurer  Tell Me Where You Are and I’ll Tell You What Y...   \n",
       "591  Stephan Daurer  Measuring Individual Search Costs on the Mobil...   \n",
       "592  Stephan Daurer  Potenziale integrierter Social Software-das Be...   \n",
       "593  Stephan Daurer  The Impact of Smartphones, Barcode Scanning, a...   \n",
       "594  Stephan Daurer  Parental control reversed: Using ADR for desig...   \n",
       "595  Stephan Daurer  Application of Media Synchronicity Theory to C...   \n",
       "596  Stephan Daurer  Consumer Preferences for Product Information a...   \n",
       "597  Stephan Daurer  iCare—supporting people with increased need fo...   \n",
       "598  Stephan Daurer  iCare – Supporting People with Increased Need ...   \n",
       "599  Stephan Daurer  Chatbots as a User Interface for Assistive Tec...   \n",
       "600  Stephan Daurer  iCare–Do-It-Yourself: Architektur ambienter As...   \n",
       "601  Stephan Daurer  Do‐It‐Yourself as a Means for Making Assistive...   \n",
       "602  Stephan Daurer                     Die Aufklärung und das Web 2.0   \n",
       "603  Stephan Daurer  Digitizing Offline Search: An Empirical Analys...   \n",
       "604  Stephan Daurer  Notfallerkennung mit ambienten Assistenzsystem...   \n",
       "605  Stephan Daurer  Sag mir, wo du bist und ich sage dir, was du w...   \n",
       "606  Stephan Daurer                    Adblocker: Bitte keine Werbung!   \n",
       "607  Stephan Daurer                                          Adblocker   \n",
       "608  Stephan Daurer  Location-based Services and Consumer Search on...   \n",
       "609  Stephan Daurer                                       IT-Strategie   \n",
       "610  Stephan Daurer             Einkauf durch mobile Suche im Internet   \n",
       "\n",
       "     PUB_YEAR                                        PUB_AUTHORS  \\\n",
       "586    2021.0              ['MA Bächle', ' S Daurer', ' A Kolb']   \n",
       "587    2016.0  ['S Daurer', ' D Molitor', ' M Spann', ' P Man...   \n",
       "588    2012.0             ['S Daurer', ' D Molitor', ' M Spann']   \n",
       "589    2018.0  ['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...   \n",
       "590    2016.0             ['M Spann', ' D Molitor', ' S Daurer']   \n",
       "591    2012.0             ['S Daurer', ' D Molitor', ' M Spann']   \n",
       "592    2006.0                          ['M Bächle', ' S Daurer']   \n",
       "593    2013.0  ['S Daurer', ' D Molitor', ' M Spann', ' P Man...   \n",
       "594    2017.0  ['T Mettler', ' M Bächle', ' S Daurer', ' A Ju...   \n",
       "595    2019.0                        ['L Furmanek', ' S Daurer']   \n",
       "596    2017.0             ['J Fölting', ' S Daurer', ' M Spann']   \n",
       "597    2016.0  ['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...   \n",
       "598    2016.0  ['M BÄCHLE', ' S DAURER', ' A JUDT', ' T METTL...   \n",
       "599    2018.0  ['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...   \n",
       "600    2017.0  ['A Judt', ' M Bächle', ' S Daurer', ' T Mettl...   \n",
       "601    2021.0  ['T Mettler', ' S Daurer', ' MA Bächle', ' A J...   \n",
       "602    2019.0                         ['MA Bächle', ' S Daurer']   \n",
       "603    2018.0  ['D Molitor', ' S Daurer', ' M Spann', ' P Man...   \n",
       "604    2017.0  ['M Bächle', ' S Daurer', ' A Judt', ' T Mettl...   \n",
       "605    2016.0             ['M Spann', ' D Molitor', ' S Daurer']   \n",
       "606    2016.0                           ['T Krohn', ' S Daurer']   \n",
       "607    2016.0                           ['S Daurer', ' T Krohn']   \n",
       "608    2014.0                                       ['S Daurer']   \n",
       "609    2013.0                                       ['S Daurer']   \n",
       "610    2013.0             ['M Spann', ' S Daurer', ' D Molitor']   \n",
       "\n",
       "                                         PUB_PUBLISHER  PUB_CITATIONS  \\\n",
       "586                              De Gruyter Oldenbourg           41.0   \n",
       "587                      Ross School of Business Paper           23.0   \n",
       "588           Zeitschrift für Betriebswirtschaft (ZfB)           22.0   \n",
       "589                       Health Policy and Technology           19.0   \n",
       "590                  GfK Marketing Intelligence Review           18.0   \n",
       "591                                               ECIS           14.0   \n",
       "592               HMD-Praxis der Wirtschaftsinformatik           10.0   \n",
       "593                                                NaN            9.0   \n",
       "594                                   ICIS Proceedings            4.0   \n",
       "595  Proceedings of the International Conference on...            3.0   \n",
       "596  Proceedings of the International Conference on...            3.0   \n",
       "597     European Journal of Epidemiology (Supplement))            3.0   \n",
       "598  Health – Exploring Complexity: An Interdiscipl...            NaN   \n",
       "599  Assistenztechnologien in der Arbeitswelt. Beit...            2.0   \n",
       "600            Smart-Future-Living-Bodensee Conference            2.0   \n",
       "601                        Information Systems Journal            NaN   \n",
       "602         Wirtschaftsinformatik und Management. DOI:            NaN   \n",
       "603                      Ross School of Business Paper            NaN   \n",
       "604                                   Usability Day XV            NaN   \n",
       "605        GfK MIR - Marketingforschung für die Praxis            NaN   \n",
       "606      Markenartikel – Fachmagazin für Markenführung            NaN   \n",
       "607  MedienWirtschaft - Zeitschrift für Medienmanag...            NaN   \n",
       "608                                             epubli            NaN   \n",
       "609  IT für Existenzgründer und junge Unternehmen -...            NaN   \n",
       "610                      WISU - Das Wirtschaftsstudium            NaN   \n",
       "\n",
       "        UPDATED  \n",
       "586  2022-03-19  \n",
       "587  2022-03-19  \n",
       "588  2022-03-19  \n",
       "589  2022-03-19  \n",
       "590  2022-03-19  \n",
       "591  2022-03-19  \n",
       "592  2022-03-19  \n",
       "593  2022-03-19  \n",
       "594  2022-03-19  \n",
       "595  2022-03-19  \n",
       "596  2022-03-19  \n",
       "597  2022-03-19  \n",
       "598  2022-03-19  \n",
       "599  2022-03-19  \n",
       "600  2022-03-19  \n",
       "601  2022-03-19  \n",
       "602  2022-03-19  \n",
       "603  2022-03-19  \n",
       "604  2022-03-19  \n",
       "605  2022-03-19  \n",
       "606  2022-03-19  \n",
       "607  2022-03-19  \n",
       "608  2022-03-19  \n",
       "609  2022-03-19  \n",
       "610  2022-03-19  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_result[pd_result[\"AUTHOR_NAME\"] == \"Stephan Daurer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
