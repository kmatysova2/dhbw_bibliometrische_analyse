{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB = True\n",
    "\n",
    "# change for different location\n",
    "# locations: \"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"\n",
    "\n",
    "location = \"ravensburg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD = re.compile(r\"\\w+\")\n",
    "\n",
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katma\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../data/2021/publications_ravensburg_rg.csv' does not exist: b'../data/2021/publications_ravensburg_rg.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f0fa322f6492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpublications_gs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../data/{current_year}/publications_{location}_gs.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpublications_rg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../data/{current_year}/publications_{location}_rg.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../data/2021/publications_ravensburg_rg.csv' does not exist: b'../data/2021/publications_ravensburg_rg.csv'"
     ]
    }
   ],
   "source": [
    "### data import ###\n",
    "# locations: \"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"\n",
    "\n",
    "J_RATINGS_SCIMAGO = pd.read_csv(f'../data/{current_year}/journal_ratings_scimago.csv', sep=\";\")\n",
    "J_RATINGS_VHB = pd.read_csv(f'../data/{current_year}/journal_ratings_vhb.csv')\n",
    "\n",
    "publications_gs = pd.read_csv(f'../data/{current_year}/publications_{location}_gs.csv')\n",
    "publications_rg = pd.read_csv(f'../data/{current_year}/publications_{location}_rg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get similarity of strings using cosine similarity\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(text1, text2):\n",
    "    \n",
    "    vector1 = text_to_vector(text1.lower())\n",
    "    vector2 = text_to_vector(text2.lower())\n",
    "\n",
    "    cosine = get_cosine(vector1, vector2)\n",
    "    \n",
    "    if cosine > 0.6:\n",
    "        similar = True\n",
    "    else:\n",
    "        similar = False\n",
    "        \n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_none_string(string1, string2):\n",
    "    \n",
    "    if string1 and not string2:\n",
    "        return string1\n",
    "    \n",
    "    elif string2 and not string1:\n",
    "        return string2\n",
    "    \n",
    "    elif string1 and string2:\n",
    "        return max([string1, string2], key=len)\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(publisher):\n",
    "    publisher = str(publisher)\n",
    "\n",
    "    rating_database = J_RATINGS_VHB\n",
    "    if publisher in rating_database['JOURNAL']:\n",
    "        rating_vhb = rating_database.loc[rating_database['JOURNAL'] == publisher, 'JQ3'].to_numpy()[0]\n",
    "        issn_vhb = rating_database.loc[rating_database['JOURNAL'] == publisher, 'ISSN'].to_numpy()[0]\n",
    "\n",
    "    elif index_similar := [i for i, x in enumerate(rating_database['JOURNAL']) if is_similar(publisher,x)]:\n",
    "        rating_vhb = rating_database.loc[index_similar[0], 'JQ3']\n",
    "        issn_vhb = rating_database.loc[index_similar[0], 'ISSN']\n",
    "\n",
    "    else:\n",
    "        rating_vhb = None\n",
    "        issn_vhb = None\n",
    "        \n",
    "    \n",
    "    rating_database = J_RATINGS_SCIMAGO\n",
    "    if publisher in rating_database['Title']:\n",
    "        rating_sci = rating_database.loc[rating_database['Title'] == publisher, 'H index'].to_numpy()[0]\n",
    "        issn_sci = rating_database.loc[rating_database['Title'] == publisher, 'Issn'].to_numpy()[0]\n",
    "\n",
    "    elif index_similar := [i for i, x in enumerate(rating_database['Title']) if is_similar(publisher,x)]:\n",
    "        rating_sci = rating_database.loc[index_similar[0], 'H index']\n",
    "        issn_sci = rating_database.loc[index_similar[0], 'Issn']\n",
    "\n",
    "    else:\n",
    "        rating_sci = None\n",
    "        issn_sci = None\n",
    "       \n",
    "\n",
    "#     if issn_vhb and issn_sci:\n",
    "#         if issn_vhb != issn_sci:\n",
    "#             print(f\"ISSN are not the same for found publisher: {publisher}.\")\n",
    "#         else:\n",
    "#             print(f\"ISSN are the same for found publisher: {publisher}.\")\n",
    "\n",
    "        \n",
    "    return rating_vhb, rating_sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_publication(row_gs, row_rg):\n",
    "    \n",
    "    title = get_not_none_string(str(row_gs['PUB_TITLE']), str(row_rg['PUB_TITLE']))\n",
    "    year = max([row_gs['PUB_YEAR'], row_rg['PUB_YEAR']])\n",
    "    publisher = get_not_none_string(str(row_gs['PUB_PUBLISHER']), str(row_rg['PUB_PUBLISHER']))\n",
    "    \n",
    "    authors_gs = [n.strip() for n in ast.literal_eval(row_gs[\"PUB_AUTHORS\"])]\n",
    "    authors_rg = [n.strip() for n in ast.literal_eval(row_rg[\"PUB_AUTHORS\"])]\n",
    "    authors = list(set(authors_gs + authors_rg))\n",
    "    \n",
    "    data = {\n",
    "        'AUTHOR_NAME': row_gs[\"AUTHOR_NAME\"],\n",
    "        'PUB_TITLE': title, \n",
    "        'PUB_YEAR': year, \n",
    "        'PUB_AUTHORS': authors,  \n",
    "        'PUB_TYPE': row_rg['PUB_TYPE'],\n",
    "        'PUB_PUBLISHER': publisher,\n",
    "        'PUB_CITATIONS': row_gs[\"PUB_CITATIONS\"],\n",
    "        'PUB_ISBN': row_rg['PUB_ISBN'],\n",
    "        'PUB_DOI': row_rg['PUB_DOI']\n",
    "       }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique names\n",
    "all_author_names = publications_test_gs['AUTHOR_NAME'].tolist() + publications_test_rg['AUTHOR_NAME'].tolist()\n",
    "all_author_names = set(all_author_names) # make unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', \n",
    "                                                      'PUB_AUTHORS', 'PUB_TYPE', 'PUB_PUBLISHER', \n",
    "                                                      'PUB_ISBN', 'PUB_DOI', 'PUB_CITATIONS', 'JOU_RATING_VHB', 'JOU_RATING_SCIMAGO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for author_name in all_author_names:\n",
    "    \n",
    "    subset_test_gs = publications_gs[publications_gs['AUTHOR_NAME'] == author_name]\n",
    "    subset_test_rg = publications_rg[publications_rg['AUTHOR_NAME'] == author_name]\n",
    "\n",
    "    leftover_rg = subset_test_rg.copy()\n",
    "\n",
    "    for index_gs, first_row_gs in subset_test_gs.iterrows():\n",
    "        match_found = False\n",
    "\n",
    "        # iterate over RG subset\n",
    "        for index_rg, row in subset_test_rg.iterrows():\n",
    "\n",
    "            # determining identical based on title and publisher\n",
    "            if is_similar(row[\"PUB_TITLE\"], first_row_gs[\"PUB_TITLE\"]) and \\\n",
    "                is_similar(str(row[\"PUB_PUBLISHER\"]), str(first_row_gs[\"PUB_PUBLISHER\"])): \n",
    "\n",
    "                match_found = True\n",
    "\n",
    "                combined_row = combine_publication(first_row_gs, row)\n",
    "                pd_result = pd_result.append(combined_row, ignore_index=True, sort=False)\n",
    "\n",
    "                # remove the found match from the subsets\n",
    "                #subset_test_gs = subset_test_gs.drop(index_gs).reset_index(drop=True)\n",
    "                if index_rg in leftover_rg.index:\n",
    "                    leftover_rg = leftover_rg.drop(index_rg)\n",
    "\n",
    "        if not match_found:\n",
    "            pd_result = pd_result.append(first_row_gs, ignore_index=True, sort=False)\n",
    "            #subset_test_gs = subset_test_gs.drop(index_gs).reset_index(drop=True)\n",
    "\n",
    "        # if there are RG articles left, append them\n",
    "        if (index_gs + 1 == len(subset_test_gs)) and (len(leftover_rg) > 0):\n",
    "            pd_result = pd_result.append(leftover_rg, ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "pd_result[['JOU_RATING_VHB', 'JOU_RATING_SCIMAGO']] = pd_result.apply(lambda row: get_ratings(row['PUB_PUBLISHER']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_result.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
