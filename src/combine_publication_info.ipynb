{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB = True\n",
    "\n",
    "locations = ['ravensburg', 'mannheim', 'heidenheim', 'karlsruhe', 'campus-horb', \n",
    "             'stuttgart', 'heilbronn', 'loerrach', 'mosbach', 'villingen-schwenningen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get similarity of strings using cosine similarity\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(text1, text2):\n",
    "    \n",
    "    vector1 = text_to_vector(str(text1).lower())\n",
    "    vector2 = text_to_vector(str(text2).lower())\n",
    "\n",
    "    cosine = get_cosine(vector1, vector2)\n",
    "    \n",
    "    if cosine > 0.6:\n",
    "        similar = True\n",
    "    else:\n",
    "        similar = False\n",
    "        \n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_none_string(string1, string2):\n",
    "    \n",
    "    if string1 and not string2:\n",
    "        return string1\n",
    "    \n",
    "    elif string2 and not string1:\n",
    "        return string2\n",
    "    \n",
    "    elif string1 and string2:\n",
    "        return max([string1, string2], key=len)\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_publication(row_gs, row_rg):\n",
    "    \n",
    "    title = get_not_none_string(str(row_gs['PUB_TITLE']), str(row_rg['PUB_TITLE']))\n",
    "    \n",
    "    # title sometimes contains information about type\n",
    "    if \"[BOOK]\" in title:\n",
    "        pub_type = \"book\"\n",
    "    else:\n",
    "        pub_type = row_rg['PUB_TYPE']\n",
    "    \n",
    "    title = re.sub(\"\\[[A-Z ]+\\]\", \"\", title)\n",
    "    \n",
    "    year = max([row_gs['PUB_YEAR'], row_rg['PUB_YEAR']])\n",
    "    publisher = get_not_none_string(str(row_gs['PUB_PUBLISHER']), str(row_rg['PUB_PUBLISHER']))\n",
    "    \n",
    "    authors_gs = [n.strip() for n in ast.literal_eval(row_gs[\"PUB_AUTHORS\"])]\n",
    "    authors_rg = [n.strip() for n in ast.literal_eval(row_rg[\"PUB_AUTHORS\"])]\n",
    "    authors = list(set(authors_gs + authors_rg))\n",
    "    \n",
    "    data = {\n",
    "        'AUTHOR_NAME': row_gs[\"AUTHOR_NAME\"],\n",
    "        'PUB_TITLE': title, \n",
    "        'PUB_YEAR': year, \n",
    "        'PUB_AUTHORS': authors,  \n",
    "        'PUB_TYPE': pub_type,\n",
    "        'PUB_PUBLISHER': publisher,\n",
    "        'PUB_CITATIONS': row_gs[\"PUB_CITATIONS\"],\n",
    "        'PUB_ISBN': row_rg['PUB_ISBN'],\n",
    "        'PUB_DOI': row_rg['PUB_DOI']\n",
    "       }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ravensburg 2022: Successfully combined publications.\n",
      "mannheim 2022: Successfully combined publications.\n",
      "heidenheim 2022: Successfully combined publications.\n",
      "karlsruhe 2022: Successfully combined publications.\n",
      "campus-horb 2022: Successfully combined publications.\n",
      "stuttgart 2022: Successfully combined publications.\n",
      "heilbronn 2022: Successfully combined publications.\n",
      "loerrach 2022: Successfully combined publications.\n",
      "mosbach 2022: Successfully combined publications.\n",
      "villingen-schwenningen 2022: Successfully combined publications.\n"
     ]
    }
   ],
   "source": [
    "for location in locations:\n",
    "\n",
    "    publications_gs = pd.read_csv(f'../data/{current_year}/publications_{location}_gs.csv')\n",
    "    publications_rg = pd.read_csv(f'../data/{current_year}/publications_{location}_rg.csv')\n",
    "\n",
    "    # get all unique names\n",
    "    all_author_names = publications_gs['AUTHOR_NAME'].tolist() + publications_rg['AUTHOR_NAME'].tolist()\n",
    "    all_author_names = set(all_author_names) # make unique\n",
    "\n",
    "    pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', \n",
    "                                      'PUB_AUTHORS', 'PUB_TYPE', 'PUB_PUBLISHER', \n",
    "                                      'PUB_ISBN', 'PUB_DOI', 'PUB_CITATIONS', \n",
    "                                        ])\n",
    "\n",
    "    if publications_gs.empty:\n",
    "        pd_result = publications_rg\n",
    "\n",
    "    elif publications_rg.empty:\n",
    "        pd_result = publications_gs\n",
    "\n",
    "    else:\n",
    "\n",
    "        for author_name in all_author_names:\n",
    "\n",
    "            subset_test_gs = publications_gs[publications_gs['AUTHOR_NAME'] == author_name]\n",
    "            subset_test_rg = publications_rg[publications_rg['AUTHOR_NAME'] == author_name]\n",
    "\n",
    "            leftover_rg = subset_test_rg.copy()\n",
    "\n",
    "            for index_gs, first_row_gs in subset_test_gs.iterrows():\n",
    "                match_found = False\n",
    "\n",
    "                # iterate over RG subset\n",
    "                for index_rg, row in subset_test_rg.iterrows():\n",
    "\n",
    "                    # determining identical based on title and publisher\n",
    "                    if is_similar(row[\"PUB_TITLE\"], first_row_gs[\"PUB_TITLE\"]): # and \\\n",
    "                        # is_similar(str(row[\"PUB_PUBLISHER\"]), str(first_row_gs[\"PUB_PUBLISHER\"])): \n",
    "\n",
    "                        match_found = True\n",
    "\n",
    "                        combined_row = combine_publication(first_row_gs, row)\n",
    "                        pd_result = pd_result.append(combined_row, ignore_index=True, sort=False)\n",
    "\n",
    "                        # remove the found match from the subsets\n",
    "                        if index_rg in leftover_rg.index:\n",
    "                            leftover_rg = leftover_rg.drop(index_rg)\n",
    "\n",
    "                if not match_found:\n",
    "                    pd_result = pd_result.append(first_row_gs, ignore_index=True, sort=False)\n",
    "\n",
    "                # if there are RG articles left, append them\n",
    "                if (index_gs + 1 == len(subset_test_gs)) and (len(leftover_rg) > 0):\n",
    "                    pd_result = pd_result.append(leftover_rg, ignore_index=True, sort=False)\n",
    "\n",
    "    if STORE_PUB:\n",
    "        pd_result.to_csv(f'../data/{current_year}/publications_{location}.csv', index=False)\n",
    "        print(f\"{location} {current_year}: Successfully combined publications.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
