{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install urllib3 --user\n",
    "#!pip install requests_html --user\n",
    "#!pip install cffi --user --version 1.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "import pandas as pd\n",
    "import requests_html\n",
    "from requests_html import AsyncHTMLSession\n",
    "from requests_html import HTMLSession\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_employee_to_employees(employees, name, job_title, location):\n",
    "    clean_name = get_name_without_title(name, location)\n",
    "    new_employee = {\"employee_name\" : name, \"first_matched_job_title\" : job_title, \"employee_name_clean\": clean_name, \"location\":location}\n",
    "    employees = employees.append(new_employee, ignore_index=True)\n",
    "    return employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(location):\n",
    "    if location == \"stuttgart\":\n",
    "        base_url = \"https://www.dhbw-\" + location + \".de\"\n",
    "        url = base_url + \"/dhbw-\" + location + \"/ansprechpersonen/\"\n",
    "    elif location == \"campus-horb\":\n",
    "        base_url = \"https://www.dhbw-\" + \"stuttgart\" + \".de\"\n",
    "        url = base_url + \"/horb/\" + location + \"/ansprechpersonen/\"\n",
    "    else:\n",
    "        base_url = \"https://www.\" + location + \".dhbw.de\"\n",
    "        url = base_url + \"/dhbw-\" + location + \"/ansprechpersonen\"\n",
    "    return url, base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_without_title(name, location):\n",
    "    \n",
    "    employee_name_splitted = name.split(\" \")\n",
    "    employee_name_clean = ''\n",
    "    \n",
    "    for part in employee_name_splitted:\n",
    "        if \".\" in part:\n",
    "            continue\n",
    "        else:\n",
    "            employee_name_clean += part.strip() + \" \"\n",
    "    if((location == \"stuttgart\") | (location == \"campus-horb\")):\n",
    "        return employee_name_clean.replace(\",\",\"\").strip()\n",
    "    else:\n",
    "        employee_name_splitted = employee_name_clean.split(\",\")\n",
    "        employee_name_clean = employee_name_splitted[1].strip() + \" \" + employee_name_splitted[0].strip()\n",
    "        return employee_name_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_others_to_employees(results, employees, location):\n",
    "    for person in results:\n",
    "        splitted_person = person.get_text().strip().split(\"\\n\")\n",
    "\n",
    "        for job_title in splitted_person[2:]:\n",
    "            job_title_formatted = job_title.strip().lower()\n",
    "            if any(x in job_title_formatted for x in job_title_match):\n",
    "                employees = add_new_employee_to_employees(employees, splitted_person[0], job_title.strip(), location)\n",
    "                break\n",
    "    return employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### employees for Ravensburg, Mannheim, Heidenheim, Karlsruhe, Campus-Horb, Stuttgart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"]\n",
    "#locations = [\"campus-horb\"]\n",
    "job_title_match = [\"akademisch\", \"professor\", \"studiengangsleiter\", \"wissenschaftlich\", \"studiengangsleitung\", \"prof.*\"]\n",
    "\n",
    "#session = HTMLSession()\n",
    "session = AsyncHTMLSession()\n",
    "\n",
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception for url: https://www.dhbw-stuttgart.de/dhbw-stuttgart/organisation/rektorat/\n"
     ]
    }
   ],
   "source": [
    "for location in locations:\n",
    "    employees = pd.DataFrame(data=None, columns=[\"employee_name\", \"first_matched_job_title\", \"employee_name_clean\"])\n",
    "    \n",
    "    url, base_url = get_url(location)\n",
    "    \n",
    "    r = await session.get(url)\n",
    "    await r.html.arender()\n",
    "    \n",
    "    page_soup = BeautifulSoup(r.html.html, \"html.parser\")\n",
    "    \n",
    "    if((location == 'stuttgart') | (location == \"campus-horb\")):\n",
    "        results = page_soup.find_all('span', class_=\"name\")\n",
    "        \n",
    "        for result in results:\n",
    "            s = result.find('a', href=True)\n",
    "\n",
    "            if s['href'].startswith(base_url):\n",
    "                person_url = s['href']\n",
    "            else:\n",
    "                person_url = base_url + s['href']    \n",
    "            \n",
    "            r = await session.get(person_url)\n",
    "            await r.html.arender()\n",
    "            soup = BeautifulSoup(r.html.html, \"html.parser\")\n",
    "\n",
    "            try:\n",
    "                person_name = soup.find(attrs={\"itemprop\":\"name\"}).string\n",
    "                person_job_title = soup.find(attrs={\"itemprop\":\"jobTitle\"}).string\n",
    "            except:\n",
    "                print(\"exception for url: \" + person_url)\n",
    "                continue\n",
    "\n",
    "            if any(x in person_job_title.lower() for x in job_title_match):\n",
    "                employees = add_new_employee_to_employees(employees, person_name, person_job_title.strip(), location)\n",
    "        \n",
    "    else:\n",
    "        if((location == 'ravensburg') | (location == 'heidenheim')):\n",
    "            people = page_soup.find_all('a', attrs={\"class\": \"accordion-toggle collapsed\", \"data-parent\":\"#accordion-dhbwcontacts-az\"})\n",
    "        else:\n",
    "            people = page_soup.find_all('a', attrs={\"class\": \"accordion-toggle collapsed\"})\n",
    "        employees = add_others_to_employees(people, employees, location)\n",
    "\n",
    "    employees.to_csv(f'../data/{current_year}/employees_{location}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "      <th>first_matched_job_title</th>\n",
       "      <th>employee_name_clean</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prof. Dipl.-Ing. Wolf Burger</td>\n",
       "      <td>Prof.* für Lehraufgaben</td>\n",
       "      <td>Wolf Burger</td>\n",
       "      <td>campus-horb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prof. Dipl.-Ing. Alfred Geisel, M.Sc.</td>\n",
       "      <td>Studiengangsleitung</td>\n",
       "      <td>Alfred Geisel</td>\n",
       "      <td>campus-horb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prof. Dr.-Ing. Joachim Grill</td>\n",
       "      <td>Studiengangsleitung</td>\n",
       "      <td>Joachim Grill</td>\n",
       "      <td>campus-horb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prof. Dr.-Ing. Jürgen Gundrum</td>\n",
       "      <td>Studiengangsleitung</td>\n",
       "      <td>Jürgen Gundrum</td>\n",
       "      <td>campus-horb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr.-Ing. Jens Häcker</td>\n",
       "      <td>Vertretungsprofessor</td>\n",
       "      <td>Jens Häcker</td>\n",
       "      <td>campus-horb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           employee_name  first_matched_job_title  \\\n",
       "0           Prof. Dipl.-Ing. Wolf Burger  Prof.* für Lehraufgaben   \n",
       "1  Prof. Dipl.-Ing. Alfred Geisel, M.Sc.      Studiengangsleitung   \n",
       "2           Prof. Dr.-Ing. Joachim Grill      Studiengangsleitung   \n",
       "3          Prof. Dr.-Ing. Jürgen Gundrum      Studiengangsleitung   \n",
       "4                   Dr.-Ing. Jens Häcker     Vertretungsprofessor   \n",
       "\n",
       "  employee_name_clean     location  \n",
       "0         Wolf Burger  campus-horb  \n",
       "1       Alfred Geisel  campus-horb  \n",
       "2       Joachim Grill  campus-horb  \n",
       "3      Jürgen Gundrum  campus-horb  \n",
       "4         Jens Häcker  campus-horb  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f'../data/{current_year}' # use your path\n",
    "all_files = glob.glob(path + \"/employees_*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.dhbw-stuttgart.de\"\n",
    "test_url = base_url + \"/dhbw-stuttgart/ansprechpersonen/\"\n",
    "\n",
    "page_soup = get_page_of_url(test_url)\n",
    "results = page_soup.find_all('span', class_=\"name\")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.DataFrame(columns=[\"employee\", \"first_matched_job_title\"])\n",
    "for result in results:\n",
    "    s = result.find('a', href=True)\n",
    "    \n",
    "    if s['href'].startswith(base_url):\n",
    "        person_url = s['href']\n",
    "    else:\n",
    "        person_url = base_url + s['href']\n",
    "    print(person_url)\n",
    "    \n",
    "    \n",
    "    soup = get_page_of_url(person_url)\n",
    "    \n",
    "    try:\n",
    "        person_name = soup.find(attrs={\"itemprop\":\"name\"}).string\n",
    "        person_job_title = soup.find(attrs={\"itemprop\":\"jobTitle\"}).string\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "        continue\n",
    "    \n",
    "    if any(x in person_job_title.lower() for x in job_title_match):        \n",
    "        new_employee = {\"employee_name\" : person_name, \"first_matched_job_title\" : person_job_title.strip()}\n",
    "        employees = employees.append(new_employee, ignore_index=True)\n",
    "    \n",
    "employees.head()\n",
    "employees.to_csv(f'../data/{current_year}/employees_{location}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_match = [\"akademisch\", \"professor\", \"studiengangsleiter\", \"wisschenschaftl\"]\n",
    "\n",
    "employees = pd.DataFrame(columns=[\"employee\", \"first_matched_job_title\"])\n",
    "\n",
    "for result in results:\n",
    "    s = result.get_text().strip().split(\"\\n\")\n",
    "    print(s)\n",
    "    for item in s[2:]:\n",
    "        item_formatted = item.strip().lower()\n",
    "        if item != None and any(x in item_formatted for x in job_title_match):\n",
    "            employees = employees.append({\"employee\" : s[0], \"first_matched_job_title\" : item.strip()}, ignore_index=True)\n",
    "            break\n",
    "\n",
    "employees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
