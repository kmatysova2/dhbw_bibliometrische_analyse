{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_GS = True\n",
    "\n",
    "# change for different location\n",
    "# locations: \"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"\n",
    "\n",
    "location = \"stuttgart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year - 1\n",
    "\n",
    "# open session for html requests\n",
    "SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author names\n",
    "pd_employees = pd.read_csv(f'../data/{current_year}/employees_{location}.csv')\n",
    "author_names = pd_employees['employee_name_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    random_wait_time = random.randint(1,3)\n",
    "    time.sleep(random_wait_time)\n",
    "\n",
    "    try:\n",
    "        response = SESSION.get(url)\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            raise requests.exceptions.RequestException(f\"Too many requests have been made. Stopped at url: {url}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id_query(soup):\n",
    "    \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        # get user ID for query\n",
    "        query_with_id = soup.find(\"h4\", class_ = \"gs_rt2\").find(\"a\").get('href')\n",
    "        \n",
    "    else:\n",
    "        query_with_id = None\n",
    "        print(f\"{author_name} does not have a profile on Google Scholar.\")\n",
    "        \n",
    "    return query_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_profile(soup):   \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(string_with_numbers):\n",
    "    if not string_with_numbers:\n",
    "        return None\n",
    "    \n",
    "    tokens = string_with_numbers.split(\" \")\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if not re.search(\"[0-9]\", token):\n",
    "            cleaned_tokens.append(token)\n",
    "    return \" \".join(cleaned_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publication_entries(soup):\n",
    "    \n",
    "    query_with_id = get_author_id_query(soup)\n",
    "    soup = None\n",
    "\n",
    "    if query_with_id != None:\n",
    "        # get HTML response for author profile\n",
    "        response = get_source(f\"https://scholar.google.com{query_with_id}&cstart=0&pagesize=1001\") # the last part is to get all entries\n",
    "\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.html.raw_html)\n",
    "\n",
    "            #get article entries\n",
    "            all_article_entries = soup.find_all(\"tr\", class_ = \"gsc_a_tr\")\n",
    "        \n",
    "    else:\n",
    "        all_article_entries = None\n",
    "        \n",
    "    return all_article_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(entry):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    number_citations = \"\"\n",
    "    \n",
    "    # get authors and journal\n",
    "    if entry.find(\"div\", class_ = \"gs_gray\"):\n",
    "        string_with_authors = entry.find(\"div\", class_ = \"gs_gray\").string\n",
    "        authors_list = string_with_authors.split(\",\")\n",
    "        \n",
    "        publisher_string = entry.find_all(\"div\", class_ = \"gs_gray\")[1].text\n",
    "        publisher = publisher_string.split(\",\")[0] #also has ISBN\n",
    "        publisher = remove_numbers(publisher)\n",
    "\n",
    "    # get title\n",
    "    if entry.find(\"a\", class_=\"gsc_a_at\"):\n",
    "        publication_title = entry.find(\"a\", class_=\"gsc_a_at\").string\n",
    "\n",
    "    # get year\n",
    "    if entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\"):\n",
    "        publication_year = entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\").string\n",
    "\n",
    "    # get number of citations\n",
    "    if entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\"):\n",
    "        number_citations = entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\").string\n",
    "        \n",
    "    \n",
    "    \n",
    "    return publication_title, publication_year, authors_list, number_citations, publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(soup, author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    all_publication_entries = get_all_publication_entries(soup)\n",
    "    \n",
    "    if all_publication_entries:\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, number_citations, publisher = get_publication_info(publication_entry)\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "            updated_list.append(datetime.date.today())\n",
    "\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'UPDATED': updated_list}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(soup, author_name):\n",
    "\n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    number_publications = 1\n",
    "    \n",
    "    if not soup or not soup.find(\"div\", id=\"gs_ab_md\"):\n",
    "        return pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS', 'UPDATED'])\n",
    "\n",
    "    search_result = soup.find(\"div\", id=\"gs_ab_md\").find(\"div\", class_=\"gs_ab_mdw\").text\n",
    "    \n",
    "    if re.search(\" [0-9]* result\", search_result):\n",
    "        number_publications = int(re.search(\" [0-9]* result\", search_result).group().strip().split(\" \")[0])\n",
    "        \n",
    "    # first page\n",
    "    \n",
    "    for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "        # and journal\n",
    "        if entry.find(\"div\", class_=\"gs_a\"):\n",
    "            # get authors\n",
    "            authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "            # get year\n",
    "            if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "            else:\n",
    "                publication_year = None\n",
    "\n",
    "            # get publisher\n",
    "            journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "            if \",\" in journal_string:\n",
    "                publisher = journal_string.split(\",\")[0]\n",
    "            else:\n",
    "                publisher = None\n",
    "                \n",
    "            publisher = remove_numbers(publisher)\n",
    "\n",
    "        # get title\n",
    "        if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "            publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "        # get number of citations\n",
    "        footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "        number_citations = None\n",
    "\n",
    "        for element in footer_elements:\n",
    "            if \"Cited by\" in element.text:\n",
    "                number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        publishers.append(publisher)\n",
    "        authors_lists.append(authors_list)\n",
    "        number_citations_list.append(number_citations)\n",
    "        author_name_list.append(author_name)\n",
    "        updated_list.append(datetime.date.today())\n",
    "\n",
    "        \n",
    "\n",
    "    # all other pages\n",
    "    for current_page in range(10, number_publications, 10):\n",
    "        next_page = get_source(f\"https://scholar.google.cz/scholar?start={current_page}&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "        soup = BeautifulSoup(next_page.html.raw_html)\n",
    "\n",
    "        for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "            # and journal\n",
    "            if entry.find(\"div\", class_=\"gs_a\"):\n",
    "                # get authors\n",
    "                authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "                # get year\n",
    "                if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                    publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "                else:\n",
    "                    publication_year = None\n",
    "\n",
    "                # get publisher\n",
    "                journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "                if \",\" in journal_string:\n",
    "                    publisher = journal_string.split(\",\")[0]\n",
    "                else:\n",
    "                    publisher = None\n",
    "                    \n",
    "                publisher = remove_numbers(publisher)\n",
    "\n",
    "            # get title\n",
    "            if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "                publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "            # get number of citations\n",
    "            footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            number_citations = None\n",
    "            \n",
    "            for element in footer_elements:\n",
    "                if \"Cited by\" in element.text:\n",
    "                    number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "            updated_list.append(datetime.date.today())\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'UPDATED': updated_list}\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names that are alrady in the database\n",
    "outcome_file = Path(f'../data/{current_year}/publications_{location}_gs.csv', index=False)\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS', 'UPDATED'])\n",
    "\n",
    "# don't use names that are recent enough\n",
    "if outcome_file.is_file():\n",
    "    pd_result = pd.read_csv(f'../data/{current_year}/publications_{location}_gs.csv')\n",
    "    authors_already_recent = []\n",
    "    \n",
    "    # update authors that have been updated more than 30 days ago\n",
    "    for author in pd_result[\"AUTHOR_NAME\"].unique():\n",
    "        if datetime.datetime.strptime(pd_result[pd_result['AUTHOR_NAME'] == author].iloc[0][\"UPDATED\"], \"%Y-%m-%d\").date() > (datetime.date.today() - datetime.timedelta(days=60)):\n",
    "            authors_already_recent.append(author)\n",
    "    \n",
    "    author_names = list(set(author_names) - set(authors_already_recent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No publications found for Julia Lucia Mayer.\n",
      "No publications found for Amelie Büchler.\n",
      "No publications found for Uwe Gaese.\n",
      "No publications found for Udo Efkes.\n",
      "No publications found for Tobias Ankele.\n",
      "No publications found for Bettina Flaiz RN.\n",
      "No publications found for Felicitas Kley.\n",
      "No publications found for Hans-Peter Gondring.\n",
      "No publications found for Veronika Seilz.\n",
      "No publications found for Jan Breitweg.\n",
      "No publications found for Antje Hackemann.\n",
      "No publications found for Gerald Merkl.\n",
      "No publications found for Roland Blümel.\n",
      "No publications found for Falko Michael Kötter.\n",
      "No publications found for Andreas Zilly.\n",
      "No publications found for Meike Grimme.\n",
      "No publications found for Vera Sinning.\n",
      "No publications found for Christian Weitert.\n",
      "No publications found for Jan Hladik.\n",
      "No publications found for Eva Hungerland.\n",
      "No publications found for Maximilian Schwing.\n",
      "No publications found for Ursula Weber.\n",
      "No publications found for Ivana Birisic.\n",
      "No publications found for Dirk Reichardt.\n",
      "No publications found for Klaus Grunwald.\n",
      "No publications found for Stefan Döttling.\n",
      "No publications found for Ingo Hettler.\n",
      "No publications found for Lisa-Marie Kreß.\n",
      "No publications found for Achim Boomers.\n",
      "No publications found for Friedrich Trautwein.\n",
      "No publications found for Gesine Hilf.\n",
      "No publications found for Torsten Maurer.\n",
      "No publications found for Rachid Nejma.\n",
      "No publications found for Stephan Schulz.\n",
      "No publications found for Wolfgang Nießen.\n",
      "No publications found for STB Uwe Schramm.\n",
      "No publications found for Maria Casado-Bernert.\n",
      "No publications found for Wolf-Florian Sommer.\n",
      "No publications found for Burkard Neumayer.\n",
      "No publications found for Matthias Rehme.\n",
      "No publications found for Marcus Schulz.\n",
      "No publications found for Annette Ullrich.\n",
      "No publications found for Kai Holzweißig.\n",
      "No publications found for Sanela Celjo-Hörhager.\n",
      "No publications found for Jacqueline Privenau.\n",
      "No publications found for Sebastian Richter.\n",
      "No publications found for Holger Wengert.\n",
      "No publications found for Monika Mages-Maurer.\n",
      "No publications found for Margarete Finkel.\n",
      "No publications found for Thilo Grundmann.\n",
      "No publications found for Sven Köhler.\n",
      "No publications found for Anke Simon.\n",
      "No publications found for Florian Simons.\n",
      "No publications found for Szabolcs Péteri.\n",
      "No publications found for Lucie Kluge.\n",
      "No publications found for Tobias Straub.\n",
      "No publications found for Rüdiger Hellig.\n",
      "No publications found for Bernd Schwinn.\n",
      "No publications found for Katrin Heeskens.\n",
      "No publications found for Judit Klein-Wiele.\n",
      "No publications found for Tom Kurdewan.\n",
      "No publications found for Georg Fehling.\n",
      "No publications found for Bernhard Lorch.\n",
      "No publications found for Christian Hürter.\n",
      "No publications found for Stefan Huf.\n",
      "No publications found for Jan Ostarhild.\n",
      "No publications found for Bernd Jöstingmeier.\n",
      "No publications found for Michael Sternberg.\n",
      "No publications found for Simon Hahn.\n",
      "No publications found for Ulrike Kienle.\n",
      "No publications found for Birgit Hein.\n",
      "No publications found for Karin Schmidt.\n",
      "No publications found for Tobias Scheel.\n",
      "No publications found for Kristina Braak.\n",
      "No publications found for Sebastian Rahn.\n",
      "No publications found for Rainer Patjens.\n",
      "No publications found for Kathrin Ripper.\n",
      "No publications found for Marion Burckhardt.\n",
      "No publications found for Daniel Grühn.\n",
      "No publications found for Andrea Steinhilber.\n",
      "No publications found for Markus Schwarzer.\n",
      "No publications found for Alfred Strey.\n",
      "No publications found for Stefan Fünfgeld.\n",
      "No publications found for Hans-Peter Lang.\n",
      "No publications found for Martin Häfele.\n",
      "No publications found for Christian Götz.\n",
      "No publications found for Jürgen Schwille.\n",
      "No publications found for Bernd Rall.\n",
      "No publications found for Natalie Hartmann.\n",
      "No publications found for Ralf Oppermann.\n",
      "No publications found for Sarah Selinka.\n",
      "No publications found for Margrit Ebinger.\n",
      "No publications found for Elisabeth Conradi.\n",
      "No publications found for Thomas Meyer.\n",
      "No publications found for Andreas Mitschele.\n",
      "No publications found for Roman Stoi.\n",
      "No publications found for Marcin Mikusz.\n",
      "No publications found for Jörg Knies.\n",
      "No publications found for Julia Dölling.\n",
      "No publications found for Uwe Schmid.\n",
      "No publications found for Sonja Wangler.\n",
      "No publications found for Yannik Knau.\n",
      "No publications found for Friedemann Stockmayer.\n",
      "No publications found for Anke Gärtner-Niemann.\n",
      "No publications found for Joachim Hirschmann.\n",
      "No publications found for Uwe Swoboda.\n",
      "No publications found for Tobias Gerhard Flämig.\n",
      "No publications found for Michael Iselborn.\n",
      "No publications found for Udo Heuser.\n",
      "No publications found for Matthias Mohr.\n",
      "No publications found for Stefan Nöst.\n",
      "No publications found for Nikolai Preiß.\n",
      "No publications found for Michael Grobosch.\n",
      "No publications found for Annabell Huber.\n",
      "No publications found for Daniel Rayment-Briggs.\n",
      "No publications found for Johannes Moosheimer.\n",
      "No publications found for Martin Wührl.\n",
      "No publications found for Dirk Hartel.\n",
      "No publications found for Monika Kochanowski.\n",
      "No publications found for Matthias Rapp.\n",
      "No publications found for Marc Kuhn.\n",
      "No publications found for Michael Knittel.\n",
      "No publications found for Roman Gruden.\n"
     ]
    }
   ],
   "source": [
    "# loop through authors and collect publications in dataframe\n",
    "\n",
    "for author_name in author_names:\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name_string = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://scholar.google.cz/scholar?hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    if has_profile(soup):\n",
    "        pd_publications = get_dataframe_with_publications(soup, author_name)\n",
    "\n",
    "    else:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(soup, author_name)\n",
    "        \n",
    "    if pd_publications.empty:\n",
    "        print(f\"No publications found for {author_name}.\")\n",
    "    \n",
    "    else:\n",
    "        pd_result = pd_result.append(pd_publications, ignore_index=True, sort=False)\n",
    "\n",
    "pd_result = pd_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_GS:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_gs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>PUB_TITLE</th>\n",
       "      <th>PUB_YEAR</th>\n",
       "      <th>PUB_AUTHORS</th>\n",
       "      <th>PUB_PUBLISHER</th>\n",
       "      <th>PUB_CITATIONS</th>\n",
       "      <th>UPDATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tobias Alf</td>\n",
       "      <td>The impact of contextual, conversational, and ...</td>\n",
       "      <td>2011</td>\n",
       "      <td>['TA Kroll', ' N Müller']</td>\n",
       "      <td>Journal of Interactional Research in …</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tobias Alf</td>\n",
       "      <td>The DUT task: A novel experimental paradigm to...</td>\n",
       "      <td>2017</td>\n",
       "      <td>['TA Kroll', ' AA Trindade', ' A Asikis…']</td>\n",
       "      <td>… and Statistics in …</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jenny Arens</td>\n",
       "      <td>1. Unterscheidung nach Immobilienarten</td>\n",
       "      <td>2015</td>\n",
       "      <td>['J Arens']</td>\n",
       "      <td>Band I Betriebswirtschaftliche Grundlagen</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenny Arens</td>\n",
       "      <td>[BOOK][B] Strategisches Reputationsmanagement ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>['J Arens ']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jenny Arens</td>\n",
       "      <td>Immobilienjournalismus in Europa</td>\n",
       "      <td>2008</td>\n",
       "      <td>['N Jackob', ' J Arens', ' T Zerback ']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>Hans Weghorn</td>\n",
       "      <td>Software Concept for Four-Dimensional Bispectr...</td>\n",
       "      <td>1997</td>\n",
       "      <td>[H Weghorn]</td>\n",
       "      <td>Science with the VLT Interferometer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Hans Weghorn</td>\n",
       "      <td>Astronomical Image Compression by Segmentation...</td>\n",
       "      <td>2005</td>\n",
       "      <td>[C Grünler,  H Weghorn,  C Chibelushi]</td>\n",
       "      <td>ITCS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Hans Weghorn</td>\n",
       "      <td>Information Technology &amp; Computer Science</td>\n",
       "      <td>2004</td>\n",
       "      <td>[H Weghorn ]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>Hans Weghorn</td>\n",
       "      <td>Applying Data Compression Methods</td>\n",
       "      <td>2004</td>\n",
       "      <td>[H Weghorn]</td>\n",
       "      <td>… an International Virtual Observatory: Proce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>Hans Weghorn</td>\n",
       "      <td>TECHNOLOGY FOR LEAST-COST NETWORK ROUTING VIA ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>[H Weghorn]</td>\n",
       "      <td>International Conference on Enterprise Inform...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1586 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUTHOR_NAME                                          PUB_TITLE  \\\n",
       "0       Tobias Alf  The impact of contextual, conversational, and ...   \n",
       "1       Tobias Alf  The DUT task: A novel experimental paradigm to...   \n",
       "2      Jenny Arens             1. Unterscheidung nach Immobilienarten   \n",
       "3      Jenny Arens  [BOOK][B] Strategisches Reputationsmanagement ...   \n",
       "4      Jenny Arens                   Immobilienjournalismus in Europa   \n",
       "...            ...                                                ...   \n",
       "1581  Hans Weghorn  Software Concept for Four-Dimensional Bispectr...   \n",
       "1582  Hans Weghorn  Astronomical Image Compression by Segmentation...   \n",
       "1583  Hans Weghorn          Information Technology & Computer Science   \n",
       "1584  Hans Weghorn                  Applying Data Compression Methods   \n",
       "1585  Hans Weghorn  TECHNOLOGY FOR LEAST-COST NETWORK ROUTING VIA ...   \n",
       "\n",
       "     PUB_YEAR                                 PUB_AUTHORS  \\\n",
       "0        2011                   ['TA Kroll', ' N Müller']   \n",
       "1        2017  ['TA Kroll', ' AA Trindade', ' A Asikis…']   \n",
       "2        2015                                 ['J Arens']   \n",
       "3        2009                                ['J Arens ']   \n",
       "4        2008     ['N Jackob', ' J Arens', ' T Zerback ']   \n",
       "...       ...                                         ...   \n",
       "1581     1997                                 [H Weghorn]   \n",
       "1582     2005      [C Grünler,  H Weghorn,  C Chibelushi]   \n",
       "1583     2004                                [H Weghorn ]   \n",
       "1584     2004                                 [H Weghorn]   \n",
       "1585     2006                                 [H Weghorn]   \n",
       "\n",
       "                                          PUB_PUBLISHER PUB_CITATIONS  \\\n",
       "0                Journal of Interactional Research in …             3   \n",
       "1                                 … and Statistics in …           NaN   \n",
       "2             Band I Betriebswirtschaftliche Grundlagen             5   \n",
       "3                                                   NaN             6   \n",
       "4                                                   NaN             5   \n",
       "...                                                 ...           ...   \n",
       "1581                Science with the VLT Interferometer           NaN   \n",
       "1582                                               ITCS           NaN   \n",
       "1583                                               None           NaN   \n",
       "1584   … an International Virtual Observatory: Proce...           NaN   \n",
       "1585   International Conference on Enterprise Inform...           NaN   \n",
       "\n",
       "         UPDATED  \n",
       "0     2022-03-04  \n",
       "1     2022-03-04  \n",
       "2     2022-03-04  \n",
       "3     2022-03-04  \n",
       "4     2022-03-04  \n",
       "...          ...  \n",
       "1581  2022-03-25  \n",
       "1582  2022-03-25  \n",
       "1583  2022-03-25  \n",
       "1584  2022-03-25  \n",
       "1585  2022-03-25  \n",
       "\n",
       "[1586 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
