{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_GS = True\n",
    "\n",
    "# change for different location\n",
    "\n",
    "# locations: ravensburg, mannheim, heidenheim, karlsruhe, campus-horb, stuttgart\n",
    "# locations: heilbronn, loerrach, mosbach, villingen-schwenningen\n",
    "\n",
    "location = \"karlsruhe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "# open session for html requests\n",
    "SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author names\n",
    "pd_employees = pd.read_csv(f'../data/{current_year}/employees_{location}.csv')\n",
    "author_names = pd_employees['employee_name_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    random_wait_time = random.randint(1,3)\n",
    "    time.sleep(random_wait_time)\n",
    "\n",
    "    try:\n",
    "        response = SESSION.get(url)\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            raise requests.exceptions.RequestException(f\"Too many requests have been made. Stopped at url: {url}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id_query(soup):\n",
    "    \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        # get user ID for query\n",
    "        query_with_id = soup.find(\"h4\", class_ = \"gs_rt2\").find(\"a\").get('href')\n",
    "        \n",
    "    else:\n",
    "        query_with_id = None\n",
    "        print(f\"{author_name} does not have a profile on Google Scholar.\")\n",
    "        \n",
    "    return query_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_profile(soup):   \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(string_with_numbers):\n",
    "    if not string_with_numbers:\n",
    "        return None\n",
    "    \n",
    "    tokens = string_with_numbers.split(\" \")\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if not re.search(\"[0-9]\", token):\n",
    "            cleaned_tokens.append(token)\n",
    "    return \" \".join(cleaned_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publication_entries(soup):\n",
    "    \n",
    "    query_with_id = get_author_id_query(soup)\n",
    "    soup = None\n",
    "\n",
    "    if query_with_id != None:\n",
    "        # get HTML response for author profile\n",
    "        response = get_source(f\"https://scholar.google.com{query_with_id}&cstart=0&pagesize=1001\") # the last part is to get all entries\n",
    "\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.html.raw_html)\n",
    "\n",
    "            #get article entries\n",
    "            all_article_entries = soup.find_all(\"tr\", class_ = \"gsc_a_tr\")\n",
    "        \n",
    "    else:\n",
    "        all_article_entries = None\n",
    "        \n",
    "    return all_article_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(entry):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    number_citations = \"\"\n",
    "    \n",
    "    # get authors and journal\n",
    "    if entry.find(\"div\", class_ = \"gs_gray\"):\n",
    "        string_with_authors = entry.find(\"div\", class_ = \"gs_gray\").string\n",
    "        authors_list = string_with_authors.split(\",\")\n",
    "        \n",
    "        publisher_string = entry.find_all(\"div\", class_ = \"gs_gray\")[1].text\n",
    "        publisher = publisher_string.split(\",\")[0] #also has ISBN\n",
    "        publisher = remove_numbers(publisher)\n",
    "\n",
    "    # get title\n",
    "    if entry.find(\"a\", class_=\"gsc_a_at\"):\n",
    "        publication_title = entry.find(\"a\", class_=\"gsc_a_at\").string\n",
    "\n",
    "    # get year\n",
    "    if entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\"):\n",
    "        publication_year = entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\").string\n",
    "\n",
    "    # get number of citations\n",
    "    if entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\"):\n",
    "        number_citations = entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\").string\n",
    "        \n",
    "    \n",
    "    \n",
    "    return publication_title, publication_year, authors_list, number_citations, publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(soup, author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    all_publication_entries = get_all_publication_entries(soup)\n",
    "    \n",
    "    if all_publication_entries:\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, number_citations, publisher = get_publication_info(publication_entry)\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "            updated_list.append(datetime.date.today())\n",
    "\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'UPDATED': updated_list}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(soup, author_name):\n",
    "\n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    number_publications = 1\n",
    "    \n",
    "    if not soup or not soup.find(\"div\", id=\"gs_ab_md\"):\n",
    "        return pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS', 'UPDATED'])\n",
    "\n",
    "    search_result = soup.find(\"div\", id=\"gs_ab_md\").find(\"div\", class_=\"gs_ab_mdw\").text\n",
    "    \n",
    "    if re.search(\" [0-9]* result\", search_result):\n",
    "        number_publications = int(re.search(\" [0-9]* result\", search_result).group().strip().split(\" \")[0])\n",
    "        \n",
    "    # first page\n",
    "    \n",
    "    for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "        # and journal\n",
    "        if entry.find(\"div\", class_=\"gs_a\"):\n",
    "            # get authors\n",
    "            authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "            # get year\n",
    "            if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "            else:\n",
    "                publication_year = None\n",
    "\n",
    "            # get publisher\n",
    "            journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "            if \",\" in journal_string:\n",
    "                publisher = journal_string.split(\",\")[0]\n",
    "            else:\n",
    "                publisher = None\n",
    "                \n",
    "            publisher = remove_numbers(publisher)\n",
    "\n",
    "        # get title\n",
    "        if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "            publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "        # get number of citations\n",
    "        footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "        number_citations = None\n",
    "\n",
    "        for element in footer_elements:\n",
    "            if \"Cited by\" in element.text:\n",
    "                number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        publishers.append(publisher)\n",
    "        authors_lists.append(authors_list)\n",
    "        number_citations_list.append(number_citations)\n",
    "        author_name_list.append(author_name)\n",
    "        updated_list.append(datetime.date.today())\n",
    "\n",
    "        \n",
    "\n",
    "    # all other pages\n",
    "    for current_page in range(10, number_publications, 10):\n",
    "        next_page = get_source(f\"https://scholar.google.cz/scholar?start={current_page}&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "        soup = BeautifulSoup(next_page.html.raw_html)\n",
    "\n",
    "        for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "            # and journal\n",
    "            if entry.find(\"div\", class_=\"gs_a\"):\n",
    "                # get authors\n",
    "                authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "                # get year\n",
    "                if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                    publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "                else:\n",
    "                    publication_year = None\n",
    "\n",
    "                # get publisher\n",
    "                journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "                if \",\" in journal_string:\n",
    "                    publisher = journal_string.split(\",\")[0]\n",
    "                else:\n",
    "                    publisher = None\n",
    "                    \n",
    "                publisher = remove_numbers(publisher)\n",
    "\n",
    "            # get title\n",
    "            if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "                publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "            # get number of citations\n",
    "            footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            number_citations = None\n",
    "            \n",
    "            for element in footer_elements:\n",
    "                if \"Cited by\" in element.text:\n",
    "                    number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "            updated_list.append(datetime.date.today())\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'UPDATED': updated_list}\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names that are alrady in the database\n",
    "outcome_file = Path(f'../data/{current_year}/publications_{location}_gs.csv', index=False)\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_CITATIONS', 'UPDATED'])\n",
    "\n",
    "# don't use names that are recent enough\n",
    "if outcome_file.is_file():\n",
    "    pd_result = pd.read_csv(f'../data/{current_year}/publications_{location}_gs.csv')\n",
    "    authors_already_recent = []\n",
    "    \n",
    "    # update authors that have been updated more than 30 days ago\n",
    "    for author in pd_result[\"AUTHOR_NAME\"].unique():\n",
    "        if datetime.datetime.strptime(pd_result[pd_result['AUTHOR_NAME'] == author].iloc[0][\"UPDATED\"], \"%Y-%m-%d\").date() > (datetime.date.today() - datetime.timedelta(days=60)):\n",
    "            authors_already_recent.append(author)\n",
    "    \n",
    "    author_names = list(set(author_names) - set(authors_already_recent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No publications found for Stephan Schenkel.\n",
      "No publications found for Jeanine von Stehlik.\n",
      "No publications found for Aneta Heinz.\n",
      "No publications found for Tanja Zeller.\n",
      "No publications found for Martin Weinmann.\n",
      "No publications found for Antje Buske.\n",
      "No publications found for Clemens Reitze.\n",
      "No publications found for Sebastian Kaufmann.\n",
      "No publications found for Monika Korbmann.\n",
      "No publications found for Andrew Lee.\n",
      "No publications found for Christian Möbius.\n",
      "No publications found for Nicole Geier.\n",
      "No publications found for Anneliese Tometten-Iseke.\n",
      "No publications found for Karsten Junge.\n",
      "No publications found for Ralf Kühn.\n",
      "No publications found for Birgit Franken.\n",
      "No publications found for Sabine Landwehr-Zloch.\n",
      "No publications found for Anne (in Elternzeit) Schreiber.\n",
      "No publications found for Michael Keller.\n",
      "No publications found for Oliver Rettig.\n",
      "No publications found for Tanja Marschall.\n",
      "No publications found for Dietlind Tittelbach-Helmrich.\n",
      "No publications found for Christiane Weiland.\n",
      "No publications found for Monika Kopra-Schäfer.\n",
      "No publications found for Markus Grün.\n",
      "No publications found for Angela Diehl-Becker.\n",
      "No publications found for Bernd Dannenmayer.\n",
      "No publications found for Kay Margarethe Berkling.\n",
      "No publications found for Michael Bauer.\n",
      "No publications found for Stefan Klink.\n",
      "No publications found for Ulf-Daniel Ehlers.\n",
      "No publications found for Florian Schwär.\n",
      "No publications found for Ralph Lausen.\n",
      "No publications found for Dirk Böhm.\n",
      "No publications found for Jürgen Röthig.\n",
      "No publications found for Gerald Oberschmidt.\n",
      "No publications found for Andreas Weber.\n",
      "No publications found for Johannes Freudenmann.\n",
      "No publications found for Eric Zimmerman.\n",
      "No publications found for Sara Brockmans.\n",
      "No publications found for Stefan Wigger.\n",
      "No publications found for Esther Rösch.\n",
      "No publications found for Regina Heck.\n",
      "No publications found for Monika Kirsch.\n",
      "No publications found for Stefan Kolb.\n",
      "No publications found for Laura Eigbrecht.\n",
      "No publications found for Silvia Lauer.\n",
      "No publications found for Klaus Grimm.\n",
      "No publications found for Rüdiger Schäfer.\n",
      "No publications found for Steffen Rasch.\n",
      "No publications found for Dirk Eidam.\n",
      "No publications found for Philipp Pohl.\n",
      "No publications found for Axel Kauffmann.\n",
      "No publications found for Evelyn Lautenschlager.\n",
      "No publications found for Ralf Dorwarth.\n",
      "No publications found for Karin Schäfer.\n",
      "No publications found for Darius Schindler.\n",
      "No publications found for Jürgen Erb.\n",
      "No publications found for Jürgen Vollmer.\n",
      "No publications found for Wibke Schmitt.\n",
      "No publications found for Mechtild Wallrath.\n",
      "No publications found for Jörn Eisenbiegler.\n",
      "No publications found for Frank Borowicz.\n",
      "No publications found for Heinrich Braun.\n",
      "No publications found for Armin Pfannenschwarz.\n",
      "No publications found for Martin Detzel.\n",
      "No publications found for Lukas Walter.\n"
     ]
    }
   ],
   "source": [
    "# loop through authors and collect publications in dataframe\n",
    "\n",
    "for author_name in author_names:\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name_string = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://scholar.google.cz/scholar?hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    if has_profile(soup):\n",
    "        pd_publications = get_dataframe_with_publications(soup, author_name)\n",
    "\n",
    "    else:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(soup, author_name)\n",
    "        \n",
    "    if pd_publications.empty:\n",
    "        print(f\"No publications found for {author_name}.\")\n",
    "    \n",
    "    else:\n",
    "        pd_result = pd_result.append(pd_publications, ignore_index=True, sort=False)\n",
    "\n",
    "pd_result = pd_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_GS:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_gs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>PUB_TITLE</th>\n",
       "      <th>PUB_YEAR</th>\n",
       "      <th>PUB_AUTHORS</th>\n",
       "      <th>PUB_PUBLISHER</th>\n",
       "      <th>PUB_CITATIONS</th>\n",
       "      <th>UPDATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Felice-Alfredo Avella</td>\n",
       "      <td>[BOOK][B] Schnelleinstieg BilMoG</td>\n",
       "      <td>2010</td>\n",
       "      <td>['FA Avella', ' R Brinkmann ']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Felice-Alfredo Avella</td>\n",
       "      <td>Substitution der Gewerbesteuer: unter Berücksi...</td>\n",
       "      <td>2004</td>\n",
       "      <td>['FA Avella ']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Felice-Alfredo Avella</td>\n",
       "      <td>[BOOK][B] Rückstellungen nach BilMoG</td>\n",
       "      <td>2011</td>\n",
       "      <td>['FA Avella', ' R Brinkmann ']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefan Reinhard</td>\n",
       "      <td>[HTML][HTML] Specific structural and compositi...</td>\n",
       "      <td>2004</td>\n",
       "      <td>[K Volz,  T Torunski,  B Kunert,  O Rubel,  S ...</td>\n",
       "      <td>Journal of crystal …</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefan Reinhard</td>\n",
       "      <td>Pruritus is associated with severely impaired ...</td>\n",
       "      <td>2014</td>\n",
       "      <td>[DN Gotthardt,  C Rupp,  M Bruhin…]</td>\n",
       "      <td>European journal of …</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Holger Becker</td>\n",
       "      <td>Hybrid tooling technologies for injection mold...</td>\n",
       "      <td>2010</td>\n",
       "      <td>[H Becker,  E Beckert,  C Gärtner]</td>\n",
       "      <td>Microfluidics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Holger Becker</td>\n",
       "      <td>From microfluidic modules to an integrated Lab...</td>\n",
       "      <td>2013</td>\n",
       "      <td>[N Hlawatsch,  M Krumbholz,  A Prüfer…]</td>\n",
       "      <td>Smart Biomedical …</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Holger Becker</td>\n",
       "      <td>Lab-on-a-chip PCR in continuous flow: an ultra...</td>\n",
       "      <td>2009</td>\n",
       "      <td>[C Gärtner,  H Becker,  T Clemens…]</td>\n",
       "      <td>… (CBRNE) Sensing X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Holger Becker</td>\n",
       "      <td>Polymer microfluidics: The technology chain</td>\n",
       "      <td>2000</td>\n",
       "      <td>[H Becker,  O Roetting,  W Roepke…]</td>\n",
       "      <td>Microfluidic Devices and …</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Holger Becker</td>\n",
       "      <td>Manufacturing issues of polymer microfluidic d...</td>\n",
       "      <td>2001</td>\n",
       "      <td>[W Röpke,  A O'Neill,  O Rötting,  J Murrihy…]</td>\n",
       "      <td>Micro Total Analysis …</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUTHOR_NAME                                          PUB_TITLE  \\\n",
       "0    Felice-Alfredo Avella                   [BOOK][B] Schnelleinstieg BilMoG   \n",
       "1    Felice-Alfredo Avella  Substitution der Gewerbesteuer: unter Berücksi...   \n",
       "2    Felice-Alfredo Avella               [BOOK][B] Rückstellungen nach BilMoG   \n",
       "3          Stefan Reinhard  [HTML][HTML] Specific structural and compositi...   \n",
       "4          Stefan Reinhard  Pruritus is associated with severely impaired ...   \n",
       "..                     ...                                                ...   \n",
       "956          Holger Becker  Hybrid tooling technologies for injection mold...   \n",
       "957          Holger Becker  From microfluidic modules to an integrated Lab...   \n",
       "958          Holger Becker  Lab-on-a-chip PCR in continuous flow: an ultra...   \n",
       "959          Holger Becker        Polymer microfluidics: The technology chain   \n",
       "960          Holger Becker  Manufacturing issues of polymer microfluidic d...   \n",
       "\n",
       "    PUB_YEAR                                        PUB_AUTHORS  \\\n",
       "0       2010                     ['FA Avella', ' R Brinkmann ']   \n",
       "1       2004                                     ['FA Avella ']   \n",
       "2       2011                     ['FA Avella', ' R Brinkmann ']   \n",
       "3       2004  [K Volz,  T Torunski,  B Kunert,  O Rubel,  S ...   \n",
       "4       2014                [DN Gotthardt,  C Rupp,  M Bruhin…]   \n",
       "..       ...                                                ...   \n",
       "956     2010                 [H Becker,  E Beckert,  C Gärtner]   \n",
       "957     2013            [N Hlawatsch,  M Krumbholz,  A Prüfer…]   \n",
       "958     2009                [C Gärtner,  H Becker,  T Clemens…]   \n",
       "959     2000                [H Becker,  O Roetting,  W Roepke…]   \n",
       "960     2001     [W Röpke,  A O'Neill,  O Rötting,  J Murrihy…]   \n",
       "\n",
       "                   PUB_PUBLISHER PUB_CITATIONS     UPDATED  \n",
       "0                            NaN           4.0  2022-04-06  \n",
       "1                            NaN           3.0  2022-04-06  \n",
       "2                            NaN           3.0  2022-04-06  \n",
       "3           Journal of crystal …          49.0  2022-04-06  \n",
       "4          European journal of …          31.0  2022-04-06  \n",
       "..                           ...           ...         ...  \n",
       "956                Microfluidics           1.0  2022-04-06  \n",
       "957           Smart Biomedical …           1.0  2022-04-06  \n",
       "958          … (CBRNE) Sensing X           1.0  2022-04-06  \n",
       "959   Microfluidic Devices and …           1.0  2022-04-06  \n",
       "960       Micro Total Analysis …           1.0  2022-04-06  \n",
       "\n",
       "[961 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
