{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_GS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "# open session for html requests\n",
    "SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    time.sleep(20)\n",
    "\n",
    "    try:\n",
    "        response = SESSION.get(url)\n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id_query(soup):\n",
    "    \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        # get user ID for query\n",
    "        query_with_id = soup.find(\"h4\", class_ = \"gs_rt2\").find(\"a\").get('href')\n",
    "        \n",
    "    else:\n",
    "        query_with_id = None\n",
    "        print(f\"{author_name} does not have a profile on Google Scholar.\")\n",
    "        \n",
    "    return query_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_profile(soup):   \n",
    "    if soup.find(\"h4\", class_ = \"gs_rt2\"): # check if is profile\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publication_entries(soup):\n",
    "    \n",
    "    query_with_id = get_author_id_query(soup)\n",
    "    soup = None\n",
    "\n",
    "    if query_with_id != None:\n",
    "        # get HTML response for author profile\n",
    "        response = get_source(f\"https://scholar.google.com{query_with_id}&cstart=0&pagesize=1001\") # the last part is to get all entries\n",
    "\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.html.raw_html)\n",
    "\n",
    "            #get article entries\n",
    "            all_article_entries = soup.find_all(\"tr\", class_ = \"gsc_a_tr\")\n",
    "        \n",
    "    else:\n",
    "        all_article_entries = None\n",
    "        \n",
    "    return all_article_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(entry):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    number_citations = \"\"\n",
    "    \n",
    "    # get authors and journal\n",
    "    if entry.find(\"div\", class_ = \"gs_gray\"):\n",
    "        string_with_authors = entry.find(\"div\", class_ = \"gs_gray\").string\n",
    "        authors_list = string_with_authors.split(\",\")\n",
    "        \n",
    "        publisher_string = entry.find_all(\"div\", class_ = \"gs_gray\")[1].text\n",
    "        publisher = publisher_string.split(\",\")[0] #also has ISBN\n",
    "\n",
    "    # get title\n",
    "    if entry.find(\"a\", class_=\"gsc_a_at\"):\n",
    "        publication_title = entry.find(\"a\", class_=\"gsc_a_at\").string\n",
    "\n",
    "    # get year\n",
    "    if entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\"):\n",
    "        publication_year = entry.find(\"span\", class_ = \"gsc_a_h gsc_a_hc gs_ibl\").string\n",
    "\n",
    "    # get number of citations\n",
    "    if entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\"):\n",
    "        number_citations = entry.find(\"a\", class_ = \"gsc_a_ac gs_ibl\").string\n",
    "        \n",
    "    \n",
    "    \n",
    "    return publication_title, publication_year, authors_list, number_citations, publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(soup, author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    \n",
    "    all_publication_entries = get_all_publication_entries(soup)\n",
    "    \n",
    "    if all_publication_entries:\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, number_citations, publisher = get_publication_info(publication_entry)\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(soup, author_name):\n",
    "\n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    publishers = []\n",
    "    authors_lists = []\n",
    "    number_citations_list = []\n",
    "    author_name_list = []\n",
    "    \n",
    "    number_publications = 1\n",
    "\n",
    "    search_result = soup.find(\"div\", id=\"gs_ab_md\").find(\"div\", class_=\"gs_ab_mdw\").text\n",
    "    \n",
    "    if re.search(\" [0-9]* result\", search_result):\n",
    "        number_publications = int(re.search(\" [0-9]* result\", search_result).group().strip().split(\" \")[0])\n",
    "        \n",
    "    # first page\n",
    "    \n",
    "    for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "        # and journal\n",
    "        if entry.find(\"div\", class_=\"gs_a\"):\n",
    "            # get authors\n",
    "            authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "            # get year\n",
    "            if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "            else:\n",
    "                publication_year = None\n",
    "\n",
    "            # get publisher\n",
    "            journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "            if \",\" in journal_string:\n",
    "                publisher = journal_string.split(\",\")[0]\n",
    "            else:\n",
    "                publisher = None\n",
    "\n",
    "        # get title\n",
    "        if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "            publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "        # get number of citations\n",
    "        footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "        number_citations = None\n",
    "\n",
    "        for element in footer_elements:\n",
    "            if \"Cited by\" in element.text:\n",
    "                number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        publishers.append(publisher)\n",
    "        authors_lists.append(authors_list)\n",
    "        number_citations_list.append(number_citations)\n",
    "        author_name_list.append(author_name)\n",
    "\n",
    "        \n",
    "\n",
    "    # all other pages\n",
    "    for current_page in range(10, number_publications, 10):\n",
    "        next_page = get_source(f\"https://scholar.google.cz/scholar?start={current_page}&hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "        soup = BeautifulSoup(next_page.html.raw_html)\n",
    "\n",
    "        for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "\n",
    "            # and journal\n",
    "            if entry.find(\"div\", class_=\"gs_a\"):\n",
    "                # get authors\n",
    "                authors_list = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[0].replace(\"\\xa0\", \"\").split(\",\")\n",
    "\n",
    "                # get year\n",
    "                if re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text):\n",
    "                    publication_year = re.search(\"[0-9]{4}\", entry.find(\"div\", class_=\"gs_a\").text).group()\n",
    "                else:\n",
    "                    publication_year = None\n",
    "\n",
    "                # get publisher\n",
    "                journal_string = entry.find(\"div\", class_=\"gs_a\").text.split(\"-\")[1]\n",
    "                if \",\" in journal_string:\n",
    "                    publisher = journal_string.split(\",\")[0]\n",
    "                else:\n",
    "                    publisher = None\n",
    "\n",
    "            # get title\n",
    "            if entry.find(\"h3\", class_=\"gs_rt\"):\n",
    "                publication_title = entry.find(\"h3\", class_=\"gs_rt\").text.replace(\"[PDF]\", \"\").strip()\n",
    "\n",
    "            # get number of citations\n",
    "            footer_elements = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            number_citations = None\n",
    "            \n",
    "            for element in footer_elements:\n",
    "                if \"Cited by\" in element.text:\n",
    "                    number_citations = int(re.search(\"[0-9]*$\", element.text).group())\n",
    "\n",
    "\n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            publishers.append(publisher)\n",
    "            authors_lists.append(authors_list)\n",
    "            number_citations_list.append(number_citations)\n",
    "            author_name_list.append(author_name)\n",
    "\n",
    "    data = {'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years,\n",
    "            'PUB_PUBLISHER': publishers,\n",
    "            'PUB_AUTHORS': authors_lists, \n",
    "            'PUB_CITATIONS': number_citations_list, \n",
    "            'AUTHOR_NAME': author_name_list}\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get HTML response for author\n",
    "author_names = [\"Katerina Matysova\"]\n",
    "#[\"Stephan Daurer\", \"Gerhard Hellstern\", \"Michael Bächle\", \"Thomas Asche\", \"Oliver Bährle\", \"Wolfgang Bihler\"]\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['PUB_TITLE', 'PUB_YEAR', 'PUB_AUTHORS', 'PUB_PUBLISHER', 'AUTHOR_NAME'])\n",
    "\n",
    "for author_name in author_names:\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name_string = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://scholar.google.cz/scholar?hl=en&as_sdt=0%2C5&as_vis=1&q=author%3A%22{author_name_string}%22&btnG=\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    if has_profile(soup):\n",
    "        pd_publications = get_dataframe_with_publications(soup, author_name)\n",
    "\n",
    "    else:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(soup, author_name)\n",
    "        \n",
    "    if pd_publications.empty:\n",
    "        print(f\"No publications found for {author_name}.\")\n",
    "    \n",
    "    else:\n",
    "        pd_result = pd_result.append(pd_publications)\n",
    "\n",
    "pd_result = pd_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>PUB_AUTHORS</th>\n",
       "      <th>PUB_CITATIONS</th>\n",
       "      <th>PUB_PUBLISHER</th>\n",
       "      <th>PUB_TITLE</th>\n",
       "      <th>PUB_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Katerina Matysova</td>\n",
       "      <td>[K Matysova ]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Evaluation of Modern Missing Data Handling Met...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUTHOR_NAME    PUB_AUTHORS PUB_CITATIONS PUB_PUBLISHER  \\\n",
       "0  Katerina Matysova  [K Matysova ]          None          None   \n",
       "\n",
       "                                           PUB_TITLE PUB_YEAR  \n",
       "0  Evaluation of Modern Missing Data Handling Met...     2019  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_result = pd_result.reset_index(drop=True)\n",
    "pd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_GS:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_test_gs.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem: \n",
    "- publisher is not fucking einheitlich"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
