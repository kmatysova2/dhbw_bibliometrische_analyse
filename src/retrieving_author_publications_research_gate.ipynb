{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_RG = True\n",
    "\n",
    "# change for different location\n",
    "# locations: \"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"\n",
    "\n",
    "location = \"ravensburg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "# open session for html requests\n",
    "SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author names\n",
    "pd_employees = pd.read_csv(f'../data/{current_year}/employees_{location}.csv')\n",
    "author_names = pd_employees['employee_name_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    random_wait_time = random.randint(20,60)\n",
    "    time.sleep(random_wait_time) # prevents captcha hopefully\n",
    "\n",
    "    try:\n",
    "        response = SESSION.get(url)\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            raise requests.exceptions.RequestException(f\"Too many requests have been made. Stopped at url: {url}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_profile(author_name):\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name = author_name.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "    query = author_name.replace(\" \", \"-\")\n",
    "    response = get_source(\"https://www.researchgate.net/profile/\" + query)\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "        \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_publication_list(author_name, page):\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name = author_name.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "    query = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://www.researchgate.net/search/publication?q=\\\"{query}\\\"&page={page}\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publications(page):\n",
    "    return page.find_all(\"div\", class_=\"nova-legacy-v-publication-item__body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publisher(publication_profile, publication_type):\n",
    "    \n",
    "    metadata = publication_profile.find(\"div\", class_=\"research-detail-header-section__metadata\")\n",
    "\n",
    "    publisher = None\n",
    "    \n",
    "    if not metadata: # don't search for publisher if no metadata\n",
    "        pass\n",
    "    \n",
    "    elif publication_type == 'Article':\n",
    "\n",
    "        if metadata.find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-decorated\"):\n",
    "            publisher = metadata.find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-decorated\").text\n",
    "\n",
    "    elif publication_type in ['Book', 'Chapter']:\n",
    "\n",
    "        if metadata.find(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "\n",
    "            # there are multiple items with that class\n",
    "            for meta in metadata.find_all(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "                if \"Publisher\" in meta.text:\n",
    "                    publisher = meta.text.split(\"Publisher: \",1)[1]\n",
    "\n",
    "    elif publication_type in ['Poster', 'Conference Paper']:\n",
    "\n",
    "        if metadata.find(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "\n",
    "            # there are multiple items with that class\n",
    "            for meta in metadata.find_all(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "                if \"Conference\" in meta.text:\n",
    "                    publisher = meta.text.split(\"Conference: \",1)[1]\n",
    "                    \n",
    "    return publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(publication_profile):\n",
    "    \n",
    "    metadata = publication_profile.find(\"div\", class_=\"research-detail-header-section__metadata\")\n",
    "\n",
    "    isbn = None\n",
    "    doi = None\n",
    "    \n",
    "    if not metadata: # don't search for identifier if no metadata\n",
    "        pass\n",
    "    \n",
    "\n",
    "    if metadata.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-m nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-xxs nova-legacy-e-text--color-grey-700\"):\n",
    "\n",
    "        # there are multiple items with that class\n",
    "        for meta in metadata.find_all(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-m nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-xxs nova-legacy-e-text--color-grey-700\"):\n",
    "            if \"ISBN\" in meta.text:\n",
    "                isbn = meta.text.split(\"ISBN:\",1)[1]\n",
    "                \n",
    "            elif \"DOI\" in meta.text:\n",
    "                doi = meta.text.split(\"DOI:\",1)[1]\n",
    "       \n",
    "    return isbn, doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(publication):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    publication_type = \"\"\n",
    "    publisher = \"\"\n",
    "    \n",
    "    # publication title\n",
    "    if publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\"):\n",
    "        publication_title = publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\").string\n",
    "\n",
    "    # publication year\n",
    "    if publication.find(\"li\", class_=\"nova-legacy-e-list__item nova-legacy-v-publication-item__meta-data-item\"):\n",
    "        publication_year_string = publication.find(\"li\", class_=\"nova-legacy-e-list__item nova-legacy-v-publication-item__meta-data-item\").string\n",
    "        publication_year = re.search(r\"([0-9]{4})\", publication_year_string).group(1) # only get year\n",
    "    \n",
    "    # authors\n",
    "    if publication.find(\"span\", class_=\"nova-legacy-v-person-inline-item__fullname\"):\n",
    "        publication_author_list = publication.find_all(\"span\", class_=\"nova-legacy-v-person-inline-item__fullname\")\n",
    "        authors_list = [x.text for x in publication_author_list]\n",
    "    \n",
    "    # publication type\n",
    "    if publication.find(\"span\", class_= \"nova-legacy-e-badge nova-legacy-e-badge--color-green nova-legacy-e-badge--display-block nova-legacy-e-badge--luminosity-high nova-legacy-e-badge--size-l nova-legacy-e-badge--theme-solid nova-legacy-e-badge--radius-m nova-legacy-v-publication-item__badge\"):\n",
    "        publication_type = publication.find(\"span\", class_= \"nova-legacy-e-badge nova-legacy-e-badge--color-green nova-legacy-e-badge--display-block nova-legacy-e-badge--luminosity-high nova-legacy-e-badge--size-l nova-legacy-e-badge--theme-solid nova-legacy-e-badge--radius-m nova-legacy-v-publication-item__badge\").text\n",
    "    \n",
    "    # publisher\n",
    "    if publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\")\\\n",
    "    .find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-bare\"):\n",
    "\n",
    "        publication_link = publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\")\\\n",
    "        .find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-bare\")['href']\n",
    "        \n",
    "        # sometimes the \n",
    "        if not publication_link.startswith(\"https://www.researchgate.net/\"):\n",
    "            publication_link = \"https://www.researchgate.net/\" + publication_link\n",
    "            \n",
    "        publication_profile = BeautifulSoup(get_source(publication_link).html.raw_html)\n",
    "        \n",
    "        publisher = get_publisher(publication_profile, publication_type)\n",
    "        isbn, doi = get_identifier(publication_profile)\n",
    "    \n",
    "    return publication_title, publication_year, authors_list, publication_type, publisher, isbn, doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(author_name):\n",
    "    author_profile = get_author_profile(author_name)\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    authors_lists = []\n",
    "    publication_types = []\n",
    "    publisher_list = []\n",
    "    author_name_list = []\n",
    "    isbn_list = []\n",
    "    doi_list = []\n",
    "\n",
    "    \n",
    "    if author_profile:\n",
    "        all_publication_entries = get_all_publications(author_profile)\n",
    "        \n",
    "    for publication_entry in all_publication_entries:\n",
    "        publication_title, publication_year, authors_list, publication_type, publisher, isbn, doi = get_publication_info(publication_entry)\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        authors_lists.append(authors_list)\n",
    "        publication_types.append(publication_type)\n",
    "        author_name_list.append(author_name)\n",
    "        publisher_list.append(publisher)\n",
    "        isbn_list.append(isbn)\n",
    "        doi_list.append(doi)\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years, \n",
    "            'PUB_AUTHORS': authors_lists,  \n",
    "            'PUB_TYPE': publication_types,\n",
    "            'PUB_PUBLISHER': publisher_list,\n",
    "            'PUB_ISBN': isbn_list,\n",
    "            'PUB_DOI': doi_list\n",
    "           }\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    authors_lists = []\n",
    "    publication_types = []\n",
    "    publisher_list = []\n",
    "    author_name_list = []\n",
    "    isbn_list = []\n",
    "    doi_list = []\n",
    "    \n",
    "    keep_going = True\n",
    "    page_number = 1\n",
    "    \n",
    "    while keep_going:\n",
    "        page_with_publications = get_author_publication_list(author_name, page_number)\n",
    "        page_number = page_number + 1 # go to next page\n",
    "        \n",
    "        all_publication_entries = get_all_publications(page_with_publications)\n",
    "        \n",
    "        if not all_publication_entries:\n",
    "            keep_going = False\n",
    "            continue\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, publication_type, publisher, isbn, doi = get_publication_info(publication_entry)\n",
    "        \n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            authors_lists.append(authors_list)\n",
    "            publication_types.append(publication_type)\n",
    "            author_name_list.append(author_name)\n",
    "            publisher_list.append(publisher)\n",
    "            isbn_list.append(isbn)\n",
    "            doi_list.append(doi)\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years, \n",
    "            'PUB_AUTHORS': authors_lists,  \n",
    "            'PUB_TYPE': publication_types,\n",
    "            'PUB_PUBLISHER': publisher_list,\n",
    "            'PUB_ISBN': isbn_list,\n",
    "            'PUB_DOI': doi_list\n",
    "           }\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No publications found for Atheer Al-Tameemi.\n",
      "Too many requests have been made. Stopped at url: https://www.researchgate.net/search/publication?q=\"Thomas+Bauer\"&page=7\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-aeaaded7104f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpd_publications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mpd_publications\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataframe_with_publications_no_profile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpd_publications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-979bbcc2b382>\u001b[0m in \u001b[0;36mget_dataframe_with_publications_no_profile\u001b[1;34m(author_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mkeep_going\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mpage_with_publications\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_author_publication_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mpage_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage_number\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# go to next page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-d375d3ad054e>\u001b[0m in \u001b[0;36mget_author_publication_list\u001b[1;34m(author_name, page)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauthor_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"+\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"https://www.researchgate.net/search/publication?q=\\\"{query}\\\"&page={page}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_html\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'html'"
     ]
    }
   ],
   "source": [
    "# loop through authors and collect publications in dataframe\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', \n",
    "                                                  'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_TYPE',\n",
    "                                                  'PUB_ISBN', 'PUB_DOI' ])\n",
    "\n",
    "for author_name in author_names:\n",
    "    # to pretend this is not a robot\n",
    "    author_query = author_name.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\").replace(\" \", \"%\")\n",
    "    get_source(f\"https://www.researchgate.net/search.Search.html?type=researcher&query={author_query}\")\n",
    "    \n",
    "    # real query\n",
    "    pd_publications = get_dataframe_with_publications(author_name)\n",
    "    \n",
    "    if pd_publications.empty:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(author_name)\n",
    "        \n",
    "        if pd_publications.empty:\n",
    "            print(f\"No publications found for {author_name}.\")\n",
    "            \n",
    "    pd_result = pd_result.append(pd_publications, ignore_index=True, sort=False)\n",
    "\n",
    "pd_result = pd_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_RG:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_rg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
