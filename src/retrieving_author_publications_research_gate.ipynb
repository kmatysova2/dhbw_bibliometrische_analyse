{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to store dataset\n",
    "STORE_PUB_RG = True\n",
    "\n",
    "# change for different location\n",
    "# locations: \"ravensburg\", \"mannheim\", \"heidenheim\", \"karlsruhe\", \"campus-horb\", \"stuttgart\"\n",
    "\n",
    "# locations: campus-horb, heidenheim, heilbronn, karlsruhe, loerrach, mannheim, mosbach, \n",
    "# ravensburg, stuttgart, villingen-schwenningen\n",
    "\n",
    "location = \"mosbach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current year to save in applicable folder\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "# open session for html requests - deprecated\n",
    "#SESSION = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author names\n",
    "pd_employees = pd.read_csv(f'../data/{current_year}/employees_{location}.csv')\n",
    "author_names = pd_employees['employee_name_clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "    random_wait_time = random.randint(5,15)\n",
    "    time.sleep(random_wait_time) # prevents captcha hopefully\n",
    "\n",
    "    try:\n",
    "        # reopen session each time to prevent timeout\n",
    "        SESSION = HTMLSession()\n",
    "        response = SESSION.get(url)\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            raise requests.exceptions.RequestException(f\"Too many requests have been made. Stopped at url: {url}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_profile(author_name):\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name = author_name.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "    query = author_name.replace(\" \", \"-\")\n",
    "    response = get_source(\"https://www.researchgate.net/profile/\" + query)\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "        \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_publication_list(author_name, page):\n",
    "    \n",
    "    # get HTML response for author\n",
    "    author_name = author_name.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "    query = author_name.replace(\" \", \"+\")\n",
    "    response = get_source(f\"https://www.researchgate.net/search/publication?q=\\\"{query}\\\"&page={page}\")\n",
    "    soup = BeautifulSoup(response.html.raw_html)\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_publications(page):\n",
    "    return page.find_all(\"div\", class_=\"nova-legacy-v-publication-item__body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publisher(publication_profile, publication_type):\n",
    "    \n",
    "    metadata = publication_profile.find(\"div\", class_=\"research-detail-header-section__metadata\")\n",
    "\n",
    "    publisher = None\n",
    "    \n",
    "    if not metadata: # don't search for publisher if no metadata\n",
    "        pass\n",
    "    \n",
    "    elif publication_type == 'Article':\n",
    "\n",
    "        if metadata.find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-decorated\"):\n",
    "            publisher = metadata.find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-decorated\").text\n",
    "\n",
    "    elif publication_type in ['Book', 'Chapter']:\n",
    "\n",
    "        if metadata.find(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "\n",
    "            # there are multiple items with that class\n",
    "            for meta in metadata.find_all(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "                if re.match(\"^Publisher: [ \\wäöüß]+$\", meta.text):\n",
    "                    publisher = meta.text.split(\"Publisher: \",1)[1]\n",
    "\n",
    "    elif publication_type in ['Poster', 'Conference Paper']:\n",
    "\n",
    "        if metadata.find(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "\n",
    "            # there are multiple items with that class\n",
    "            for meta in metadata.find_all(\"li\", class_=\"nova-legacy-e-list__item\"):\n",
    "                if re.match(\"^Conference: [ \\wäöüß]+$\", meta.text):\n",
    "                    publisher = meta.text.split(\"Conference: \",1)[1]\n",
    "                    \n",
    "    return publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(publication_profile):\n",
    "    \n",
    "    metadata = publication_profile.find(\"div\", class_=\"research-detail-header-section__metadata\")\n",
    "\n",
    "    isbn = None\n",
    "    doi = None\n",
    "    \n",
    "    if not metadata: # don't search for identifier if no metadata\n",
    "        pass\n",
    "    \n",
    "\n",
    "    if metadata.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-m nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-xxs nova-legacy-e-text--color-grey-700\"):\n",
    "\n",
    "        # there are multiple items with that class\n",
    "        for meta in metadata.find_all(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-m nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-xxs nova-legacy-e-text--color-grey-700\"):\n",
    "            if \"ISBN\" in meta.text:\n",
    "                isbn = meta.text.split(\"ISBN:\",1)[1]\n",
    "                \n",
    "            elif \"DOI\" in meta.text:\n",
    "                doi = meta.text.split(\"DOI:\",1)[1]\n",
    "       \n",
    "    return isbn, doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_info(publication):\n",
    "    \n",
    "    publication_title = \"\"\n",
    "    publication_year = \"\"\n",
    "    authors_list = []\n",
    "    publication_type = \"\"\n",
    "    publisher = \"\"\n",
    "    \n",
    "    # publication title\n",
    "    if publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\"):\n",
    "        publication_title = publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\").string\n",
    "\n",
    "    # publication year\n",
    "    if publication.find(\"li\", class_=\"nova-legacy-e-list__item nova-legacy-v-publication-item__meta-data-item\"):\n",
    "        publication_year_string = publication.find(\"li\", class_=\"nova-legacy-e-list__item nova-legacy-v-publication-item__meta-data-item\").string\n",
    "        publication_year = re.search(r\"([0-9]{4})\", publication_year_string).group(1) # only get year\n",
    "    \n",
    "    # authors\n",
    "    if publication.find(\"span\", class_=\"nova-legacy-v-person-inline-item__fullname\"):\n",
    "        publication_author_list = publication.find_all(\"span\", class_=\"nova-legacy-v-person-inline-item__fullname\")\n",
    "        authors_list = [x.text for x in publication_author_list]\n",
    "    \n",
    "    # publication type\n",
    "    if publication.find(\"span\", class_= \"nova-legacy-e-badge nova-legacy-e-badge--color-green nova-legacy-e-badge--display-block nova-legacy-e-badge--luminosity-high nova-legacy-e-badge--size-l nova-legacy-e-badge--theme-solid nova-legacy-e-badge--radius-m nova-legacy-v-publication-item__badge\"):\n",
    "        publication_type = publication.find(\"span\", class_= \"nova-legacy-e-badge nova-legacy-e-badge--color-green nova-legacy-e-badge--display-block nova-legacy-e-badge--luminosity-high nova-legacy-e-badge--size-l nova-legacy-e-badge--theme-solid nova-legacy-e-badge--radius-m nova-legacy-v-publication-item__badge\").text\n",
    "    \n",
    "    # publisher\n",
    "    if publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\")\\\n",
    "    .find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-bare\"):\n",
    "\n",
    "        publication_link = publication.find(\"div\", class_=\"nova-legacy-e-text nova-legacy-e-text--size-l nova-legacy-e-text--family-sans-serif nova-legacy-e-text--spacing-none nova-legacy-e-text--color-inherit nova-legacy-v-publication-item__title\")\\\n",
    "        .find(\"a\", class_=\"nova-legacy-e-link nova-legacy-e-link--color-inherit nova-legacy-e-link--theme-bare\")['href']\n",
    "        \n",
    "        # sometimes the \n",
    "        if not publication_link.startswith(\"https://www.researchgate.net/\"):\n",
    "            publication_link = \"https://www.researchgate.net/\" + publication_link\n",
    "            \n",
    "        publication_profile = BeautifulSoup(get_source(publication_link).html.raw_html)\n",
    "        \n",
    "        publisher = get_publisher(publication_profile, publication_type)\n",
    "        isbn, doi = get_identifier(publication_profile)\n",
    "    \n",
    "    return publication_title, publication_year, authors_list, publication_type, publisher, isbn, doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications(author_name):\n",
    "    author_profile = get_author_profile(author_name)\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    authors_lists = []\n",
    "    publication_types = []\n",
    "    publisher_list = []\n",
    "    author_name_list = []\n",
    "    isbn_list = []\n",
    "    doi_list = []\n",
    "    updated_list = []\n",
    "\n",
    "    \n",
    "    if author_profile:\n",
    "        all_publication_entries = get_all_publications(author_profile)\n",
    "        \n",
    "    for publication_entry in all_publication_entries:\n",
    "        publication_title, publication_year, authors_list, publication_type, publisher, isbn, doi = get_publication_info(publication_entry)\n",
    "\n",
    "        publication_titles.append(publication_title)\n",
    "        publication_years.append(publication_year)\n",
    "        authors_lists.append(authors_list)\n",
    "        publication_types.append(publication_type)\n",
    "        author_name_list.append(author_name)\n",
    "        publisher_list.append(publisher)\n",
    "        isbn_list.append(isbn)\n",
    "        doi_list.append(doi)\n",
    "        updated_list.append(datetime.date.today())\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years, \n",
    "            'PUB_AUTHORS': authors_lists,  \n",
    "            'PUB_TYPE': publication_types,\n",
    "            'PUB_PUBLISHER': publisher_list,\n",
    "            'PUB_ISBN': isbn_list,\n",
    "            'PUB_DOI': doi_list,\n",
    "            'UPDATED': updated_list\n",
    "           }\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_publications_no_profile(author_name):\n",
    "    \n",
    "    publication_titles = []\n",
    "    publication_years = []\n",
    "    authors_lists = []\n",
    "    publication_types = []\n",
    "    publisher_list = []\n",
    "    author_name_list = []\n",
    "    isbn_list = []\n",
    "    doi_list = []\n",
    "    updated_list = []\n",
    "    \n",
    "    keep_going = True\n",
    "    page_number = 1\n",
    "    \n",
    "    while keep_going:\n",
    "        page_with_publications = get_author_publication_list(author_name, page_number)\n",
    "        page_number = page_number + 1 # go to next page\n",
    "        \n",
    "        all_publication_entries = get_all_publications(page_with_publications)\n",
    "        \n",
    "        if not all_publication_entries:\n",
    "            keep_going = False\n",
    "            continue\n",
    "        \n",
    "        for publication_entry in all_publication_entries:\n",
    "            publication_title, publication_year, authors_list, publication_type, publisher, isbn, doi = get_publication_info(publication_entry)\n",
    "        \n",
    "            publication_titles.append(publication_title)\n",
    "            publication_years.append(publication_year)\n",
    "            authors_lists.append(authors_list)\n",
    "            publication_types.append(publication_type)\n",
    "            author_name_list.append(author_name)\n",
    "            publisher_list.append(publisher)\n",
    "            isbn_list.append(isbn)\n",
    "            doi_list.append(doi)\n",
    "            updated_list.append(datetime.date.today())\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "            'AUTHOR_NAME': author_name_list,\n",
    "            'PUB_TITLE': publication_titles, \n",
    "            'PUB_YEAR': publication_years, \n",
    "            'PUB_AUTHORS': authors_lists,  \n",
    "            'PUB_TYPE': publication_types,\n",
    "            'PUB_PUBLISHER': publisher_list,\n",
    "            'PUB_ISBN': isbn_list,\n",
    "            'PUB_DOI': doi_list,\n",
    "            'UPDATED': updated_list\n",
    "           }\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names that are alrady in the database\n",
    "outcome_file = Path(f'../data/{current_year}/publications_{location}_rg.csv', index=False)\n",
    "\n",
    "pd_result = pd.DataFrame(columns=['AUTHOR_NAME', 'PUB_TITLE', 'PUB_YEAR', \n",
    "                                                  'PUB_AUTHORS', 'PUB_PUBLISHER', 'PUB_TYPE',\n",
    "                                                  'PUB_ISBN', 'PUB_DOI', 'UPDATED'])\n",
    "\n",
    "# don't use names that are recent enough\n",
    "if outcome_file.is_file():\n",
    "    pd_result = pd.read_csv(f'../data/{current_year}/publications_{location}_rg.csv')\n",
    "    authors_already_recent = []\n",
    "    \n",
    "    # update authors that have been updated more than 30 days ago\n",
    "    for author in pd_result[\"AUTHOR_NAME\"].unique():\n",
    "        if datetime.datetime.strptime(pd_result[pd_result['AUTHOR_NAME'] == author].iloc[0][\"UPDATED\"], \"%Y-%m-%d\").date() > (datetime.date.today() - datetime.timedelta(days=60)):\n",
    "            authors_already_recent.append(author)\n",
    "    \n",
    "    author_names = list(set(author_names) - set(authors_already_recent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through authors and collect publications in dataframe\n",
    "\n",
    "for author_name in author_names:\n",
    "    \n",
    "    # real query\n",
    "    pd_publications = get_dataframe_with_publications(author_name)\n",
    "    \n",
    "    if pd_publications.empty:\n",
    "        pd_publications = get_dataframe_with_publications_no_profile(author_name)\n",
    "        \n",
    "        if pd_publications.empty:\n",
    "            print(f\"No publications found for {author_name}.\")\n",
    "            \n",
    "    pd_result = pd_result.append(pd_publications, ignore_index=True, sort=False)\n",
    "\n",
    "    # save each time since it breaks all the time\n",
    "    pd_result = pd_result.reset_index(drop=True)\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_rg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_PUB_RG:\n",
    "    pd_result.to_csv(f'../data/{current_year}/publications_{location}_rg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
